{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN DB-StyleGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training options:\n",
      "{\n",
      "  \"num_gpus\": 1,\n",
      "  \"GPU_DEVICE_NUMBER\": 0,\n",
      "  \"image_snapshot_ticks\": 20,\n",
      "  \"network_snapshot_ticks\": 20,\n",
      "  \"metrics\": [\n",
      "    \"fid50k_full\"\n",
      "  ],\n",
      "  \"random_seed\": 0,\n",
      "  \"training_set_kwargs\": {\n",
      "    \"class_name\": \"training_scripts_DB_SG2.dataset.ImageFolderDataset\",\n",
      "    \"path\": \"DATASETS/tufts_256_poses_1-7_aligned/train/images\",\n",
      "    \"use_labels\": false,\n",
      "    \"max_size\": 1965,\n",
      "    \"xflip\": true,\n",
      "    \"resolution\": 256\n",
      "  },\n",
      "  \"data_loader_kwargs\": {\n",
      "    \"pin_memory\": true,\n",
      "    \"num_workers\": 3,\n",
      "    \"prefetch_factor\": 2\n",
      "  },\n",
      "  \"G_kwargs\": {\n",
      "    \"class_name\": \"training_scripts_DB_SG2.networks.Generator\",\n",
      "    \"z_dim\": 512,\n",
      "    \"w_dim\": 512,\n",
      "    \"mapping_kwargs\": {\n",
      "      \"num_layers\": 8\n",
      "    },\n",
      "    \"synthesis_kwargs\": {\n",
      "      \"channel_base\": 16384,\n",
      "      \"channel_max\": 512,\n",
      "      \"num_fp16_res\": 4,\n",
      "      \"conv_clamp\": 256\n",
      "    }\n",
      "  },\n",
      "  \"D_kwargs\": {\n",
      "    \"class_name\": \"training_scripts_DB_SG2.networks.Discriminator\",\n",
      "    \"block_kwargs\": {},\n",
      "    \"mapping_kwargs\": {},\n",
      "    \"epilogue_kwargs\": {\n",
      "      \"mbstd_group_size\": 4\n",
      "    },\n",
      "    \"channel_base\": 16384,\n",
      "    \"channel_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_kwargs\": {\n",
      "    \"class_name\": \"torch.optim.Adam\",\n",
      "    \"lr\": 0.0025,\n",
      "    \"betas\": [\n",
      "      0,\n",
      "      0.99\n",
      "    ],\n",
      "    \"eps\": 1e-08\n",
      "  },\n",
      "  \"D_opt_kwargs\": {\n",
      "    \"class_name\": \"torch.optim.Adam\",\n",
      "    \"lr\": 0.0025,\n",
      "    \"betas\": [\n",
      "      0,\n",
      "      0.99\n",
      "    ],\n",
      "    \"eps\": 1e-08\n",
      "  },\n",
      "  \"loss_kwargs\": {\n",
      "    \"class_name\": \"training_scripts_DB_SG2.loss.StyleGAN2Loss\",\n",
      "    \"r1_gamma\": 0.8192\n",
      "  },\n",
      "  \"total_kimg\": 10000,\n",
      "  \"batch_size\": 12,\n",
      "  \"batch_gpu\": 12,\n",
      "  \"ema_kimg\": 5.0,\n",
      "  \"ema_rampup\": null,\n",
      "  \"ada_target\": 0.6,\n",
      "  \"augment_kwargs\": {\n",
      "    \"class_name\": \"training_scripts_DB_SG2.augment.AugmentPipe\",\n",
      "    \"xflip\": 1,\n",
      "    \"rotate90\": 1,\n",
      "    \"xint\": 1,\n",
      "    \"scale\": 1,\n",
      "    \"rotate\": 1,\n",
      "    \"aniso\": 1,\n",
      "    \"xfrac\": 1,\n",
      "    \"brightness\": 1,\n",
      "    \"contrast\": 1,\n",
      "    \"lumaflip\": 1,\n",
      "    \"hue\": 1,\n",
      "    \"saturation\": 1\n",
      "  },\n",
      "  \"resume_pkl\": \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/transfer-learning-source-nets/ffhq-res256-mirror-paper256-noaug.pkl\",\n",
      "  \"ada_kimg\": 100,\n",
      "  \"run_dir\": \"EXPERIMENTS/DB_SG2/EXPERIMENT_tufts_256_poses_1-7_aligned_loss_one_tenth/00000-images-mirror-auto1-batch12-resumeffhq256\"\n",
      "}\n",
      "\n",
      "Output directory:   EXPERIMENTS/DB_SG2/EXPERIMENT_tufts_256_poses_1-7_aligned_loss_one_tenth/00000-images-mirror-auto1-batch12-resumeffhq256\n",
      "Training data:      DATASETS/tufts_256_poses_1-7_aligned/train/images\n",
      "Training duration:  10000 kimg\n",
      "Number of GPUs:     1\n",
      "Number of images:   1965\n",
      "Image resolution:   256\n",
      "Conditional model:  False\n",
      "Dataset x-flips:    True\n",
      "\n",
      "Creating output directory...\n",
      "Launching processes...\n",
      "Loading training set...\n",
      "DATASET PARAMS {'class_name': 'training_scripts_DB_SG2.dataset.ImageFolderDataset', 'path': 'DATASETS/tufts_256_poses_1-7_aligned/train/images', 'use_labels': False, 'max_size': 1965, 'xflip': True, 'resolution': 256}\n",
      "\n",
      "Num images:  3930\n",
      "Image shape: [3, 256, 256]\n",
      "Label shape: [0]\n",
      "\n",
      "Constructing networks...\n",
      "Synthesis network:\n",
      "- Block resolutions: [4, 8, 16, 32, 64, 128, 256]\n",
      "- Channels dict: {4: 512, 8: 512, 16: 512, 32: 512, 64: 256, 128: 128, 256: 64}\n",
      "Discriminator network: \n",
      "- Channels dict  {256: 64, 128: 128, 64: 256, 32: 512, 16: 512, 8: 512, 4: 512}\n",
      "- BLock resolutions: [256, 128, 64, 32, 16, 8]\n",
      "{'class_name': 'training_scripts_DB_SG2.networks.Discriminator', 'block_kwargs': {}, 'mapping_kwargs': {}, 'epilogue_kwargs': {'mbstd_group_size': 4}, 'channel_base': 16384, 'channel_max': 512, 'num_fp16_res': 4, 'conv_clamp': 256}\n",
      "{'c_dim': 0, 'img_resolution': 256, 'img_channels': 3}\n",
      "Discriminator network: \n",
      "- Channels dict  {256: 64, 128: 128, 64: 256, 32: 512, 16: 512, 8: 512, 4: 512}\n",
      "- BLock resolutions: [256, 128, 64, 32, 16, 8]\n",
      "Resuming from \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/transfer-learning-source-nets/ffhq-res256-mirror-paper256-noaug.pkl\"\n",
      "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/transfer-learning-source-nets/ffhq-res256-mirror-paper256-noaug.pkl ... done\n",
      "G\n",
      "synthesis.b4.const\n",
      "synthesis.b4.conv1.weight\n",
      "synthesis.b4.conv1.noise_strength\n",
      "synthesis.b4.conv1.bias\n",
      "synthesis.b4.conv1.affine.weight\n",
      "synthesis.b4.conv1.affine.bias\n",
      "synthesis.b4.torgb.weight\n",
      "synthesis.b4.torgb.bias\n",
      "synthesis.b4.torgb.affine.weight\n",
      "synthesis.b4.torgb.affine.bias\n",
      "synthesis.b8.conv0.weight\n",
      "synthesis.b8.conv0.noise_strength\n",
      "synthesis.b8.conv0.bias\n",
      "synthesis.b8.conv0.affine.weight\n",
      "synthesis.b8.conv0.affine.bias\n",
      "synthesis.b8.conv1.weight\n",
      "synthesis.b8.conv1.noise_strength\n",
      "synthesis.b8.conv1.bias\n",
      "synthesis.b8.conv1.affine.weight\n",
      "synthesis.b8.conv1.affine.bias\n",
      "synthesis.b8.torgb.weight\n",
      "synthesis.b8.torgb.bias\n",
      "synthesis.b8.torgb.affine.weight\n",
      "synthesis.b8.torgb.affine.bias\n",
      "synthesis.b16.conv0.weight\n",
      "synthesis.b16.conv0.noise_strength\n",
      "synthesis.b16.conv0.bias\n",
      "synthesis.b16.conv0.affine.weight\n",
      "synthesis.b16.conv0.affine.bias\n",
      "synthesis.b16.conv1.weight\n",
      "synthesis.b16.conv1.noise_strength\n",
      "synthesis.b16.conv1.bias\n",
      "synthesis.b16.conv1.affine.weight\n",
      "synthesis.b16.conv1.affine.bias\n",
      "synthesis.b16.torgb.weight\n",
      "synthesis.b16.torgb.bias\n",
      "synthesis.b16.torgb.affine.weight\n",
      "synthesis.b16.torgb.affine.bias\n",
      "synthesis.b32.conv0.weight\n",
      "synthesis.b32.conv0.noise_strength\n",
      "synthesis.b32.conv0.bias\n",
      "synthesis.b32.conv0.affine.weight\n",
      "synthesis.b32.conv0.affine.bias\n",
      "synthesis.b32.conv1.weight\n",
      "synthesis.b32.conv1.noise_strength\n",
      "synthesis.b32.conv1.bias\n",
      "synthesis.b32.conv1.affine.weight\n",
      "synthesis.b32.conv1.affine.bias\n",
      "synthesis.b32.torgb.weight\n",
      "synthesis.b32.torgb.bias\n",
      "synthesis.b32.torgb.affine.weight\n",
      "synthesis.b32.torgb.affine.bias\n",
      "synthesis.b64.conv0.weight\n",
      "synthesis.b64.conv0.noise_strength\n",
      "synthesis.b64.conv0.bias\n",
      "synthesis.b64.conv0.affine.weight\n",
      "synthesis.b64.conv0.affine.bias\n",
      "synthesis.b64.conv1.weight\n",
      "synthesis.b64.conv1.noise_strength\n",
      "synthesis.b64.conv1.bias\n",
      "synthesis.b64.conv1.affine.weight\n",
      "synthesis.b64.conv1.affine.bias\n",
      "synthesis.b64.torgb.weight\n",
      "synthesis.b64.torgb.bias\n",
      "synthesis.b64.torgb.affine.weight\n",
      "synthesis.b64.torgb.affine.bias\n",
      "synthesis.b128.conv0.weight\n",
      "synthesis.b128.conv0.noise_strength\n",
      "synthesis.b128.conv0.bias\n",
      "synthesis.b128.conv0.affine.weight\n",
      "synthesis.b128.conv0.affine.bias\n",
      "synthesis.b128.conv1.weight\n",
      "synthesis.b128.conv1.noise_strength\n",
      "synthesis.b128.conv1.bias\n",
      "synthesis.b128.conv1.affine.weight\n",
      "synthesis.b128.conv1.affine.bias\n",
      "synthesis.b128.torgb.weight\n",
      "synthesis.b128.torgb.bias\n",
      "synthesis.b128.torgb.affine.weight\n",
      "synthesis.b128.torgb.affine.bias\n",
      "synthesis.b256.conv0.weight\n",
      "synthesis.b256.conv0.noise_strength\n",
      "synthesis.b256.conv0.bias\n",
      "synthesis.b256.conv0.affine.weight\n",
      "synthesis.b256.conv0.affine.bias\n",
      "synthesis.b256.conv1.weight\n",
      "synthesis.b256.conv1.noise_strength\n",
      "synthesis.b256.conv1.bias\n",
      "synthesis.b256.conv1.affine.weight\n",
      "synthesis.b256.conv1.affine.bias\n",
      "synthesis.b256.torgb.weight\n",
      "synthesis.b256.torgb.bias\n",
      "synthesis.b256.torgb.affine.weight\n",
      "synthesis.b256.torgb.affine.bias\n",
      "mapping.fc0.weight\n",
      "mapping.fc0.bias\n",
      "mapping.fc1.weight\n",
      "mapping.fc1.bias\n",
      "mapping.fc2.weight\n",
      "mapping.fc2.bias\n",
      "mapping.fc3.weight\n",
      "mapping.fc3.bias\n",
      "mapping.fc4.weight\n",
      "mapping.fc4.bias\n",
      "mapping.fc5.weight\n",
      "mapping.fc5.bias\n",
      "mapping.fc6.weight\n",
      "mapping.fc6.bias\n",
      "mapping.fc7.weight\n",
      "mapping.fc7.bias\n",
      "synthesis.b4.resample_filter\n",
      "synthesis.b4.conv1.resample_filter\n",
      "synthesis.b4.conv1.noise_const\n",
      "synthesis.b8.resample_filter\n",
      "synthesis.b8.conv0.resample_filter\n",
      "synthesis.b8.conv0.noise_const\n",
      "synthesis.b8.conv1.resample_filter\n",
      "synthesis.b8.conv1.noise_const\n",
      "synthesis.b16.resample_filter\n",
      "synthesis.b16.conv0.resample_filter\n",
      "synthesis.b16.conv0.noise_const\n",
      "synthesis.b16.conv1.resample_filter\n",
      "synthesis.b16.conv1.noise_const\n",
      "synthesis.b32.resample_filter\n",
      "synthesis.b32.conv0.resample_filter\n",
      "synthesis.b32.conv0.noise_const\n",
      "synthesis.b32.conv1.resample_filter\n",
      "synthesis.b32.conv1.noise_const\n",
      "synthesis.b64.resample_filter\n",
      "synthesis.b64.conv0.resample_filter\n",
      "synthesis.b64.conv0.noise_const\n",
      "synthesis.b64.conv1.resample_filter\n",
      "synthesis.b64.conv1.noise_const\n",
      "synthesis.b128.resample_filter\n",
      "synthesis.b128.conv0.resample_filter\n",
      "synthesis.b128.conv0.noise_const\n",
      "synthesis.b128.conv1.resample_filter\n",
      "synthesis.b128.conv1.noise_const\n",
      "synthesis.b256.resample_filter\n",
      "synthesis.b256.conv0.resample_filter\n",
      "synthesis.b256.conv0.noise_const\n",
      "synthesis.b256.conv1.resample_filter\n",
      "synthesis.b256.conv1.noise_const\n",
      "mapping.w_avg\n",
      "D\n",
      "b256.fromrgb.weight\n",
      "b256.fromrgb.bias\n",
      "b256.conv0.weight\n",
      "b256.conv0.bias\n",
      "b256.conv1.weight\n",
      "b256.conv1.bias\n",
      "b256.skip.weight\n",
      "b128.conv0.weight\n",
      "b128.conv0.bias\n",
      "b128.conv1.weight\n",
      "b128.conv1.bias\n",
      "b128.skip.weight\n",
      "b64.conv0.weight\n",
      "b64.conv0.bias\n",
      "b64.conv1.weight\n",
      "b64.conv1.bias\n",
      "b64.skip.weight\n",
      "b32.conv0.weight\n",
      "b32.conv0.bias\n",
      "b32.conv1.weight\n",
      "b32.conv1.bias\n",
      "b32.skip.weight\n",
      "b16.conv0.weight\n",
      "b16.conv0.bias\n",
      "b16.conv1.weight\n",
      "b16.conv1.bias\n",
      "b16.skip.weight\n",
      "b8.conv0.weight\n",
      "b8.conv0.bias\n",
      "b8.conv1.weight\n",
      "b8.conv1.bias\n",
      "b8.skip.weight\n",
      "b4.conv.weight\n",
      "b4.conv.bias\n",
      "b4.fc.weight\n",
      "b4.fc.bias\n",
      "b4.out.weight\n",
      "b4.out.bias\n",
      "b256.resample_filter\n",
      "b256.fromrgb.resample_filter\n",
      "b256.conv0.resample_filter\n",
      "b256.conv1.resample_filter\n",
      "b256.skip.resample_filter\n",
      "b128.resample_filter\n",
      "b128.conv0.resample_filter\n",
      "b128.conv1.resample_filter\n",
      "b128.skip.resample_filter\n",
      "b64.resample_filter\n",
      "b64.conv0.resample_filter\n",
      "b64.conv1.resample_filter\n",
      "b64.skip.resample_filter\n",
      "b32.resample_filter\n",
      "b32.conv0.resample_filter\n",
      "b32.conv1.resample_filter\n",
      "b32.skip.resample_filter\n",
      "b16.resample_filter\n",
      "b16.conv0.resample_filter\n",
      "b16.conv1.resample_filter\n",
      "b16.skip.resample_filter\n",
      "b8.resample_filter\n",
      "b8.conv0.resample_filter\n",
      "b8.conv1.resample_filter\n",
      "b8.skip.resample_filter\n",
      "b4.conv.resample_filter\n",
      "G_ema\n",
      "synthesis.b4.const\n",
      "synthesis.b4.conv1.weight\n",
      "synthesis.b4.conv1.noise_strength\n",
      "synthesis.b4.conv1.bias\n",
      "synthesis.b4.conv1.affine.weight\n",
      "synthesis.b4.conv1.affine.bias\n",
      "synthesis.b4.torgb.weight\n",
      "synthesis.b4.torgb.bias\n",
      "synthesis.b4.torgb.affine.weight\n",
      "synthesis.b4.torgb.affine.bias\n",
      "synthesis.b8.conv0.weight\n",
      "synthesis.b8.conv0.noise_strength\n",
      "synthesis.b8.conv0.bias\n",
      "synthesis.b8.conv0.affine.weight\n",
      "synthesis.b8.conv0.affine.bias\n",
      "synthesis.b8.conv1.weight\n",
      "synthesis.b8.conv1.noise_strength\n",
      "synthesis.b8.conv1.bias\n",
      "synthesis.b8.conv1.affine.weight\n",
      "synthesis.b8.conv1.affine.bias\n",
      "synthesis.b8.torgb.weight\n",
      "synthesis.b8.torgb.bias\n",
      "synthesis.b8.torgb.affine.weight\n",
      "synthesis.b8.torgb.affine.bias\n",
      "synthesis.b16.conv0.weight\n",
      "synthesis.b16.conv0.noise_strength\n",
      "synthesis.b16.conv0.bias\n",
      "synthesis.b16.conv0.affine.weight\n",
      "synthesis.b16.conv0.affine.bias\n",
      "synthesis.b16.conv1.weight\n",
      "synthesis.b16.conv1.noise_strength\n",
      "synthesis.b16.conv1.bias\n",
      "synthesis.b16.conv1.affine.weight\n",
      "synthesis.b16.conv1.affine.bias\n",
      "synthesis.b16.torgb.weight\n",
      "synthesis.b16.torgb.bias\n",
      "synthesis.b16.torgb.affine.weight\n",
      "synthesis.b16.torgb.affine.bias\n",
      "synthesis.b32.conv0.weight\n",
      "synthesis.b32.conv0.noise_strength\n",
      "synthesis.b32.conv0.bias\n",
      "synthesis.b32.conv0.affine.weight\n",
      "synthesis.b32.conv0.affine.bias\n",
      "synthesis.b32.conv1.weight\n",
      "synthesis.b32.conv1.noise_strength\n",
      "synthesis.b32.conv1.bias\n",
      "synthesis.b32.conv1.affine.weight\n",
      "synthesis.b32.conv1.affine.bias\n",
      "synthesis.b32.torgb.weight\n",
      "synthesis.b32.torgb.bias\n",
      "synthesis.b32.torgb.affine.weight\n",
      "synthesis.b32.torgb.affine.bias\n",
      "synthesis.b64.conv0.weight\n",
      "synthesis.b64.conv0.noise_strength\n",
      "synthesis.b64.conv0.bias\n",
      "synthesis.b64.conv0.affine.weight\n",
      "synthesis.b64.conv0.affine.bias\n",
      "synthesis.b64.conv1.weight\n",
      "synthesis.b64.conv1.noise_strength\n",
      "synthesis.b64.conv1.bias\n",
      "synthesis.b64.conv1.affine.weight\n",
      "synthesis.b64.conv1.affine.bias\n",
      "synthesis.b64.torgb.weight\n",
      "synthesis.b64.torgb.bias\n",
      "synthesis.b64.torgb.affine.weight\n",
      "synthesis.b64.torgb.affine.bias\n",
      "synthesis.b128.conv0.weight\n",
      "synthesis.b128.conv0.noise_strength\n",
      "synthesis.b128.conv0.bias\n",
      "synthesis.b128.conv0.affine.weight\n",
      "synthesis.b128.conv0.affine.bias\n",
      "synthesis.b128.conv1.weight\n",
      "synthesis.b128.conv1.noise_strength\n",
      "synthesis.b128.conv1.bias\n",
      "synthesis.b128.conv1.affine.weight\n",
      "synthesis.b128.conv1.affine.bias\n",
      "synthesis.b128.torgb.weight\n",
      "synthesis.b128.torgb.bias\n",
      "synthesis.b128.torgb.affine.weight\n",
      "synthesis.b128.torgb.affine.bias\n",
      "synthesis.b256.conv0.weight\n",
      "synthesis.b256.conv0.noise_strength\n",
      "synthesis.b256.conv0.bias\n",
      "synthesis.b256.conv0.affine.weight\n",
      "synthesis.b256.conv0.affine.bias\n",
      "synthesis.b256.conv1.weight\n",
      "synthesis.b256.conv1.noise_strength\n",
      "synthesis.b256.conv1.bias\n",
      "synthesis.b256.conv1.affine.weight\n",
      "synthesis.b256.conv1.affine.bias\n",
      "synthesis.b256.torgb.weight\n",
      "synthesis.b256.torgb.bias\n",
      "synthesis.b256.torgb.affine.weight\n",
      "synthesis.b256.torgb.affine.bias\n",
      "mapping.fc0.weight\n",
      "mapping.fc0.bias\n",
      "mapping.fc1.weight\n",
      "mapping.fc1.bias\n",
      "mapping.fc2.weight\n",
      "mapping.fc2.bias\n",
      "mapping.fc3.weight\n",
      "mapping.fc3.bias\n",
      "mapping.fc4.weight\n",
      "mapping.fc4.bias\n",
      "mapping.fc5.weight\n",
      "mapping.fc5.bias\n",
      "mapping.fc6.weight\n",
      "mapping.fc6.bias\n",
      "mapping.fc7.weight\n",
      "mapping.fc7.bias\n",
      "synthesis.b4.resample_filter\n",
      "synthesis.b4.conv1.resample_filter\n",
      "synthesis.b4.conv1.noise_const\n",
      "synthesis.b8.resample_filter\n",
      "synthesis.b8.conv0.resample_filter\n",
      "synthesis.b8.conv0.noise_const\n",
      "synthesis.b8.conv1.resample_filter\n",
      "synthesis.b8.conv1.noise_const\n",
      "synthesis.b16.resample_filter\n",
      "synthesis.b16.conv0.resample_filter\n",
      "synthesis.b16.conv0.noise_const\n",
      "synthesis.b16.conv1.resample_filter\n",
      "synthesis.b16.conv1.noise_const\n",
      "synthesis.b32.resample_filter\n",
      "synthesis.b32.conv0.resample_filter\n",
      "synthesis.b32.conv0.noise_const\n",
      "synthesis.b32.conv1.resample_filter\n",
      "synthesis.b32.conv1.noise_const\n",
      "synthesis.b64.resample_filter\n",
      "synthesis.b64.conv0.resample_filter\n",
      "synthesis.b64.conv0.noise_const\n",
      "synthesis.b64.conv1.resample_filter\n",
      "synthesis.b64.conv1.noise_const\n",
      "synthesis.b128.resample_filter\n",
      "synthesis.b128.conv0.resample_filter\n",
      "synthesis.b128.conv0.noise_const\n",
      "synthesis.b128.conv1.resample_filter\n",
      "synthesis.b128.conv1.noise_const\n",
      "synthesis.b256.resample_filter\n",
      "synthesis.b256.conv0.resample_filter\n",
      "synthesis.b256.conv0.noise_const\n",
      "synthesis.b256.conv1.resample_filter\n",
      "synthesis.b256.conv1.noise_const\n",
      "mapping.w_avg\n",
      "Discriminator(\n",
      "  (b256): DiscriminatorBlock(\n",
      "    (fromrgb): Conv2dLayer()\n",
      "    (conv0): Conv2dLayer()\n",
      "    (conv1): Conv2dLayer()\n",
      "    (skip): Conv2dLayer()\n",
      "  )\n",
      "  (b128): DiscriminatorBlock(\n",
      "    (conv0): Conv2dLayer()\n",
      "    (conv1): Conv2dLayer()\n",
      "    (skip): Conv2dLayer()\n",
      "  )\n",
      "  (b64): DiscriminatorBlock(\n",
      "    (conv0): Conv2dLayer()\n",
      "    (conv1): Conv2dLayer()\n",
      "    (skip): Conv2dLayer()\n",
      "  )\n",
      "  (b32): DiscriminatorBlock(\n",
      "    (conv0): Conv2dLayer()\n",
      "    (conv1): Conv2dLayer()\n",
      "    (skip): Conv2dLayer()\n",
      "  )\n",
      "  (b16): DiscriminatorBlock(\n",
      "    (conv0): Conv2dLayer()\n",
      "    (conv1): Conv2dLayer()\n",
      "    (skip): Conv2dLayer()\n",
      "  )\n",
      "  (b8): DiscriminatorBlock(\n",
      "    (conv0): Conv2dLayer()\n",
      "    (conv1): Conv2dLayer()\n",
      "    (skip): Conv2dLayer()\n",
      "  )\n",
      "  (b4): DiscriminatorEpilogue(\n",
      "    (mbstd): MinibatchStdLayer()\n",
      "    (conv): Conv2dLayer()\n",
      "    (fc): FullyConnectedLayer()\n",
      "    (out): FullyConnectedLayer()\n",
      "  )\n",
      ")\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "\n",
      "Generator               Parameters  Buffers  Output shape         Datatype\n",
      "---                     ---         ---      ---                  ---     \n",
      "mapping.fc0             262656      -        [12, 512]            float32 \n",
      "mapping.fc1             262656      -        [12, 512]            float32 \n",
      "mapping.fc2             262656      -        [12, 512]            float32 \n",
      "mapping.fc3             262656      -        [12, 512]            float32 \n",
      "mapping.fc4             262656      -        [12, 512]            float32 \n",
      "mapping.fc5             262656      -        [12, 512]            float32 \n",
      "mapping.fc6             262656      -        [12, 512]            float32 \n",
      "mapping.fc7             262656      -        [12, 512]            float32 \n",
      "mapping                 -           512      [12, 14, 512]        float32 \n",
      "synthesis.b4.conv1:0    2622465     32       [12, 512, 4, 4]      float32 \n",
      "synthesis.b4.conv1:1    -           -        [12, 512, 4, 4]      float32 \n",
      "synthesis.b4.torgb      264195      -        [12, 3, 4, 4]        float32 \n",
      "synthesis.b4.toseg      263169      -        [12, 1, 4, 4]        float32 \n",
      "synthesis.b4:0          8192        16       [12, 512, 4, 4]      float32 \n",
      "synthesis.b4:1          -           -        [12, 512, 4, 4]      float32 \n",
      "synthesis.b4:2          -           -        [12, 512, 4, 4]      float32 \n",
      "synthesis.b4:3          -           -        [12, 512, 4, 4]      float32 \n",
      "synthesis.b8.conv0      2622465     80       [12, 512, 8, 8]      float32 \n",
      "synthesis.b8.conv1:0    2622465     80       [12, 512, 8, 8]      float32 \n",
      "synthesis.b8.conv1:1    -           -        [12, 512, 8, 8]      float32 \n",
      "synthesis.b8.torgb      264195      -        [12, 3, 8, 8]        float32 \n",
      "synthesis.b8.toseg      263169      -        [12, 1, 8, 8]        float32 \n",
      "synthesis.b8:0          -           16       [12, 512, 8, 8]      float32 \n",
      "synthesis.b8:1          -           -        [12, 512, 8, 8]      float32 \n",
      "synthesis.b8:2          -           -        [12, 512, 8, 8]      float32 \n",
      "synthesis.b8:3          -           -        [12, 512, 8, 8]      float32 \n",
      "synthesis.b16.conv0     2622465     272      [12, 512, 16, 16]    float32 \n",
      "synthesis.b16.conv1:0   2622465     272      [12, 512, 16, 16]    float32 \n",
      "synthesis.b16.conv1:1   -           -        [12, 512, 16, 16]    float32 \n",
      "synthesis.b16.torgb     264195      -        [12, 3, 16, 16]      float32 \n",
      "synthesis.b16.toseg     263169      -        [12, 1, 16, 16]      float32 \n",
      "synthesis.b16:0         -           16       [12, 512, 16, 16]    float32 \n",
      "synthesis.b16:1         -           -        [12, 512, 16, 16]    float32 \n",
      "synthesis.b16:2         -           -        [12, 512, 16, 16]    float32 \n",
      "synthesis.b16:3         -           -        [12, 512, 16, 16]    float32 \n",
      "synthesis.b32.conv0     2622465     1040     [12, 512, 32, 32]    float16 \n",
      "synthesis.b32.conv1:0   2622465     1040     [12, 512, 32, 32]    float16 \n",
      "synthesis.b32.conv1:1   -           -        [12, 512, 32, 32]    float16 \n",
      "synthesis.b32.torgb     264195      -        [12, 3, 32, 32]      float16 \n",
      "synthesis.b32.toseg     263169      -        [12, 1, 32, 32]      float16 \n",
      "synthesis.b32:0         -           16       [12, 512, 32, 32]    float16 \n",
      "synthesis.b32:1         -           -        [12, 512, 32, 32]    float16 \n",
      "synthesis.b32:2         -           -        [12, 512, 32, 32]    float32 \n",
      "synthesis.b32:3         -           -        [12, 512, 32, 32]    float32 \n",
      "synthesis.b64.conv0     1442561     4112     [12, 256, 64, 64]    float16 \n",
      "synthesis.b64.conv1:0   721409      4112     [12, 256, 64, 64]    float16 \n",
      "synthesis.b64.conv1:1   -           -        [12, 256, 64, 64]    float16 \n",
      "synthesis.b64.torgb     132099      -        [12, 3, 64, 64]      float16 \n",
      "synthesis.b64.toseg     131585      -        [12, 1, 64, 64]      float16 \n",
      "synthesis.b64:0         -           16       [12, 256, 64, 64]    float16 \n",
      "synthesis.b64:1         -           -        [12, 256, 64, 64]    float16 \n",
      "synthesis.b64:2         -           -        [12, 256, 64, 64]    float32 \n",
      "synthesis.b64:3         -           -        [12, 256, 64, 64]    float32 \n",
      "synthesis.b128.conv0    426369      16400    [12, 128, 128, 128]  float16 \n",
      "synthesis.b128.conv1:0  213249      16400    [12, 128, 128, 128]  float16 \n",
      "synthesis.b128.conv1:1  -           -        [12, 128, 128, 128]  float16 \n",
      "synthesis.b128.torgb    66051       -        [12, 3, 128, 128]    float16 \n",
      "synthesis.b128.toseg    65793       -        [12, 1, 128, 128]    float16 \n",
      "synthesis.b128:0        -           16       [12, 128, 128, 128]  float16 \n",
      "synthesis.b128:1        -           -        [12, 128, 128, 128]  float16 \n",
      "synthesis.b128:2        -           -        [12, 128, 128, 128]  float32 \n",
      "synthesis.b128:3        -           -        [12, 128, 128, 128]  float32 \n",
      "synthesis.b256.conv0    139457      65552    [12, 64, 256, 256]   float16 \n",
      "synthesis.b256.conv1:0  69761       65552    [12, 64, 256, 256]   float16 \n",
      "synthesis.b256.conv1:1  -           -        [12, 64, 256, 256]   float16 \n",
      "synthesis.b256.torgb    33027       -        [12, 3, 256, 256]    float16 \n",
      "synthesis.b256.toseg    32897       -        [12, 1, 256, 256]    float16 \n",
      "synthesis.b256:0        -           16       [12, 64, 256, 256]   float16 \n",
      "synthesis.b256:1        -           -        [12, 64, 256, 256]   float16 \n",
      "synthesis.b256:2        -           -        [12, 64, 256, 256]   float32 \n",
      "synthesis.b256:3        -           -        [12, 64, 256, 256]   float32 \n",
      "---                     ---         ---      ---                  ---     \n",
      "Total                   26050409    175568   -                    -       \n",
      "\n",
      "Generator output shape: torch.Size([12, 3, 256, 256])\n",
      "\n",
      "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
      "---            ---         ---      ---                  ---     \n",
      "b256.fromrgb   256         16       [12, 64, 256, 256]   float16 \n",
      "b256.skip      8192        16       [12, 128, 128, 128]  float16 \n",
      "b256.conv0     36928       16       [12, 64, 256, 256]   float16 \n",
      "b256.conv1     73856       16       [12, 128, 128, 128]  float16 \n",
      "b256           -           16       [12, 128, 128, 128]  float16 \n",
      "b128.skip      32768       16       [12, 256, 64, 64]    float16 \n",
      "b128.conv0     147584      16       [12, 128, 128, 128]  float16 \n",
      "b128.conv1     295168      16       [12, 256, 64, 64]    float16 \n",
      "b128           -           16       [12, 256, 64, 64]    float16 \n",
      "b64.skip       131072      16       [12, 512, 32, 32]    float16 \n",
      "b64.conv0      590080      16       [12, 256, 64, 64]    float16 \n",
      "b64.conv1      1180160     16       [12, 512, 32, 32]    float16 \n",
      "b64            -           16       [12, 512, 32, 32]    float16 \n",
      "b32.skip       262144      16       [12, 512, 16, 16]    float16 \n",
      "b32.conv0      2359808     16       [12, 512, 32, 32]    float16 \n",
      "b32.conv1      2359808     16       [12, 512, 16, 16]    float16 \n",
      "b32            -           16       [12, 512, 16, 16]    float16 \n",
      "b16.skip       262144      16       [12, 512, 8, 8]      float32 \n",
      "b16.conv0      2359808     16       [12, 512, 16, 16]    float32 \n",
      "b16.conv1      2359808     16       [12, 512, 8, 8]      float32 \n",
      "b16            -           16       [12, 512, 8, 8]      float32 \n",
      "b8.skip        262144      16       [12, 512, 4, 4]      float32 \n",
      "b8.conv0       2359808     16       [12, 512, 8, 8]      float32 \n",
      "b8.conv1       2359808     16       [12, 512, 4, 4]      float32 \n",
      "b8             -           16       [12, 512, 4, 4]      float32 \n",
      "b4.mbstd       -           -        [12, 513, 4, 4]      float32 \n",
      "b4.conv        2364416     16       [12, 512, 4, 4]      float32 \n",
      "b4.fc          4194816     -        [12, 512]            float32 \n",
      "b4.out         513         -        [12, 1]              float32 \n",
      "---            ---         ---      ---                  ---     \n",
      "Total          24001089    416      -                    -       \n",
      "\n",
      "\n",
      "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
      "---            ---         ---      ---                  ---     \n",
      "b256.fromrgb   128         16       [12, 64, 256, 256]   float16 \n",
      "b256.skip      8192        16       [12, 128, 128, 128]  float16 \n",
      "b256.conv0     36928       16       [12, 64, 256, 256]   float16 \n",
      "b256.conv1     73856       16       [12, 128, 128, 128]  float16 \n",
      "b256           -           16       [12, 128, 128, 128]  float16 \n",
      "b128.skip      32768       16       [12, 256, 64, 64]    float16 \n",
      "b128.conv0     147584      16       [12, 128, 128, 128]  float16 \n",
      "b128.conv1     295168      16       [12, 256, 64, 64]    float16 \n",
      "b128           -           16       [12, 256, 64, 64]    float16 \n",
      "b64.skip       131072      16       [12, 512, 32, 32]    float16 \n",
      "b64.conv0      590080      16       [12, 256, 64, 64]    float16 \n",
      "b64.conv1      1180160     16       [12, 512, 32, 32]    float16 \n",
      "b64            -           16       [12, 512, 32, 32]    float16 \n",
      "b32.skip       262144      16       [12, 512, 16, 16]    float16 \n",
      "b32.conv0      2359808     16       [12, 512, 32, 32]    float16 \n",
      "b32.conv1      2359808     16       [12, 512, 16, 16]    float16 \n",
      "b32            -           16       [12, 512, 16, 16]    float16 \n",
      "b16.skip       262144      16       [12, 512, 8, 8]      float32 \n",
      "b16.conv0      2359808     16       [12, 512, 16, 16]    float32 \n",
      "b16.conv1      2359808     16       [12, 512, 8, 8]      float32 \n",
      "b16            -           16       [12, 512, 8, 8]      float32 \n",
      "b8.skip        262144      16       [12, 512, 4, 4]      float32 \n",
      "b8.conv0       2359808     16       [12, 512, 8, 8]      float32 \n",
      "b8.conv1       2359808     16       [12, 512, 4, 4]      float32 \n",
      "b8             -           16       [12, 512, 4, 4]      float32 \n",
      "b4.mbstd       -           -        [12, 513, 4, 4]      float32 \n",
      "b4.conv        2364416     16       [12, 512, 4, 4]      float32 \n",
      "b4.fc          4194816     -        [12, 512]            float32 \n",
      "b4.out         513         -        [12, 1]              float32 \n",
      "---            ---         ---      ---                  ---     \n",
      "Total          24000961    416      -                    -       \n",
      "\n",
      "Setting up augmentation...\n",
      "Distributing across 1 GPUs...\n",
      "Setting up training phases...\n",
      "Exporting sample images...\n",
      "(480, 3, 256, 256)\n",
      "Initializing logs...\n",
      "Training for 10000 kimg...\n",
      "\n",
      "tick 0     kimg 0.0      time 1m 21s       sec/tick 5.8     sec/kimg 482.20  maintenance 74.8   cpumem 5.33   gpumem 7.97   augment 0.000\n",
      "Evaluating metrics...\n",
      "-- Compute metric: fid50k_full  of  1\n",
      "Compute features of the dataset\n",
      "Compute features of generator\n",
      "^C\n",
      "\n",
      "Aborted!\n"
     ]
    }
   ],
   "source": [
    "# !bash ./docker_run.sh python train_DB_StyleGAN2.py --cfg=\"auto\" --snap=20  --data=\"DATASETS/VIS-TH_Eurocom_256x256_only_normal/images\" --resume=\"ffhq256\" --gpus=1 --mirror=1 --outdir=\"IJCB_EXPERIMENTS/DB_SG2/EXPERIMENT_VIS-TH_Eurocom_256x256_only_normal_NO_VALID\"\n",
    "\n",
    "# !bash ./docker_run.sh python train_DB_StyleGAN2.py --cfg=\"auto\" --snap=20  --data=\"DATASETS/Oulu_CASIA_VIS_NIR_256x256/images\" --resume=\"ffhq256\" --gpus=1 --mirror=1 --outdir=\"IJCB_EXPERIMENTS/DB_SG2/EXPERIMENT_Oulu_CASIA_VIS_NIR_256x256_only_strong\"\n",
    "\n",
    "#!bash ./docker_run.sh python train_DB_StyleGAN2.py --cfg=\"auto\" --snap=20  --data=\"DATASETS/Tufts_256_center/images\" --resume=\"ffhq256\" --gpus=1 --mirror=1 --outdir=\"EXPERIMENTS/DB_SG2/EXPERIMENT_Tufts_256_center\"\n",
    "\n",
    "# Batch 8 \n",
    "# !bash ./docker_run.sh python train_DB_StyleGAN2.py --cfg=\"auto\" --snap=20 --gpus=1 --mirror=1 --GPU_DEVICE_NUMBER=0 --batch=12  --data=\"DATASETS/Tufts_256_center/train/images\" --resume=\"ffhq256\"  --outdir=\"EXPERIMENTS/DB_SG2/EXPERIMENT_tufts_256_poses_3-5\"\n",
    "\n",
    "!bash ./docker_run.sh python train_DB_StyleGAN2.py --cfg=\"auto\" --snap=20 --gpus=1 --mirror=1 --GPU_DEVICE_NUMBER=0 --batch=12  --data=\"DATASETS/tufts_256_poses_1-7_aligned/train/images\" --resume=\"ffhq256\"  --outdir=\"EXPERIMENTS/DB_SG2/EXPERIMENT_tufts_256_poses_1-7_aligned_loss_one_tenth\"\n",
    "\n",
    "# resume from tenth\n",
    "#!bash ./docker_run.sh python train_DB_StyleGAN2.py --cfg=\"auto\" --snap=20 --gpus=1 --mirror=1 --GPU_DEVICE_NUMBER=0 --batch=12  --data=\"DATASETS/tufts_256_poses_1-7_aligned/train/images\" --resume=\"EXPERIMENTS/checkpoints/FRAIS_2022_checkpoints/Tufts_1-7_aligned_one_tenth-001683.pkl\"  --outdir=\"EXPERIMENTS/DB_SG2/EXPERIMENT_tufts_256_poses_1-7_aligned_loss_one_tenth_continue_equal\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Use Style Interpreter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Training Images with DB-SG2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"CrossEyed_NIR_RGB_new_1120\"\n",
    "path = \"TUFTS_1-7_nonaligned_cfg_256\"\n",
    "\n",
    "exp = \"EXPERIMENTS/interpreter/FRAIS_2022/\" + path\n",
    "sv_path = \"EXPERIMENTS/interpreter/FRAIS_2022/\" + path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"make_training_data_DB_SG2.py\", line 285, in <module>\n",
      "    opts = json.load(open(args.exp, 'r'))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'EXPERIMENTS/interpreter/FRAIS_2022/TUFTS_1-7_nonaligned_cfg_256/generate.json'\n"
     ]
    }
   ],
   "source": [
    "exp_generate = exp + \"/generate.json\" \n",
    "\n",
    "samples = 100 # 100\n",
    "# GENERATE training images\n",
    "!bash docker_run.sh python make_training_data_DB_SG2.py --exp=$exp_generate --sv_path=$sv_path --num_sample=$samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermediate Steps\n",
    "\n",
    "### 1.1 Annotate the Generated Images as written in the instructions\n",
    "### 1.2 Rename latent_stylegan to back_latent_stylegan \n",
    "### 1.3 Run preprocessing script (or use your own preprocessing to obtain the required files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train Style Interpreter on Annotated Data \n",
    "\n",
    "First create generate and train json files based on the templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "Opt {'exp_dir': 'IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2', 'batch_size': 64, 'category': 'eyes_256', 'debug': False, 'dim': [256, 256, 4992], 'deeplab_res': 256, 'number_class': 4, 'testing_data_number_class': 4, 'max_training': 2, 'stylegan_ver': '2', 'annotation_data_from_w': False, 'annotation_mask_path': 'eyes_processed', 'testing_path': '', 'average_latent': 'avg_latent_stylegan.npy', 'annotation_image_latent_path': 'latent_stylegan.npy', 'stylegan_checkpoint': 'IJCB_EXPERIMENTS/checkpoints/IJCB_2022_checkpoints/CrossEyed_NIR_RGB_NEW_001120.pkl', 'model_num': 10, 'upsample_mode': 'bilinear', 'upsample_threshold': '8'}\n",
      "cp: 'IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/train_datagan.json' and 'IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/train_datagan.json' are the same file\n",
      "Prepare data\n",
      "-- Prepare stylegan\n",
      "Eyes category\n",
      "---- Resolution: 256  Layers: 7\n",
      "---- Get avg latent\n",
      "---- Latent to torch\n",
      "AVG latent torch.Size([14, 512])\n",
      "----  Build Generator\n",
      "Resuming from \"IJCB_EXPERIMENTS/checkpoints/IJCB_2022_checkpoints/CrossEyed_NIR_RGB_NEW_001120.pkl\"\n",
      "Prepare StytleGAN2\n",
      "{'ref_gpus': 1, 'kimg': 25000, 'mb': -1, 'mbstd': -1, 'fmaps': -1, 'lrate': -1, 'gamma': -1, 'ema': -1, 'ramp': 0.05, 'map': 8}\n",
      "{'class_name': 'training_scripts_DB_SG2.networks.Generator', 'z_dim': 512, 'w_dim': 512, 'mapping_kwargs': {'num_layers': 8}, 'synthesis_kwargs': {'save_intermediate_results': True, 'channel_base': 16384, 'channel_max': 512, 'num_fp16_res': 4, 'conv_clamp': 256}}\n",
      "{'c_dim': 0, 'img_resolution': 256, 'img_channels': 3}\n",
      "Synthesis network:\n",
      "- Block resolutions: [4, 8, 16, 32, 64, 128, 256]\n",
      "- Channels dict: {4: 512, 8: 512, 16: 512, 32: 512, 64: 256, 128: 128, 256: 64}\n",
      "Generator(\n",
      "  (synthesis): SynthesisNetwork(\n",
      "    (b4): SynthesisBlock(\n",
      "      (conv1): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (torgb): ToRGBLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (toseg): ToSEGLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "    )\n",
      "    (b8): SynthesisBlock(\n",
      "      (conv0): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (conv1): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (torgb): ToRGBLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (toseg): ToSEGLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "    )\n",
      "    (b16): SynthesisBlock(\n",
      "      (conv0): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (conv1): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (torgb): ToRGBLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (toseg): ToSEGLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "    )\n",
      "    (b32): SynthesisBlock(\n",
      "      (conv0): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (conv1): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (torgb): ToRGBLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (toseg): ToSEGLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "    )\n",
      "    (b64): SynthesisBlock(\n",
      "      (conv0): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (conv1): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (torgb): ToRGBLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (toseg): ToSEGLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "    )\n",
      "    (b128): SynthesisBlock(\n",
      "      (conv0): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (conv1): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (torgb): ToRGBLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (toseg): ToSEGLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "    )\n",
      "    (b256): SynthesisBlock(\n",
      "      (conv0): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (conv1): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (torgb): ToRGBLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (toseg): ToSEGLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mapping): MappingNetwork(\n",
      "    (fc0): FullyConnectedLayer()\n",
      "    (fc1): FullyConnectedLayer()\n",
      "    (fc2): FullyConnectedLayer()\n",
      "    (fc3): FullyConnectedLayer()\n",
      "    (fc4): FullyConnectedLayer()\n",
      "    (fc5): FullyConnectedLayer()\n",
      "    (fc6): FullyConnectedLayer()\n",
      "    (fc7): FullyConnectedLayer()\n",
      "  )\n",
      ")\n",
      "Resuming from \"IJCB_EXPERIMENTS/checkpoints/IJCB_2022_checkpoints/CrossEyed_NIR_RGB_NEW_001120.pkl\"\n",
      "synthesis.b4.const\n",
      "synthesis.b4.conv1.weight\n",
      "synthesis.b4.conv1.noise_strength\n",
      "synthesis.b4.conv1.bias\n",
      "synthesis.b4.conv1.affine.weight\n",
      "synthesis.b4.conv1.affine.bias\n",
      "synthesis.b4.torgb.weight\n",
      "synthesis.b4.torgb.bias\n",
      "synthesis.b4.torgb.affine.weight\n",
      "synthesis.b4.torgb.affine.bias\n",
      "synthesis.b4.toseg.weight\n",
      "synthesis.b4.toseg.bias\n",
      "synthesis.b4.toseg.affine.weight\n",
      "synthesis.b4.toseg.affine.bias\n",
      "synthesis.b8.conv0.weight\n",
      "synthesis.b8.conv0.noise_strength\n",
      "synthesis.b8.conv0.bias\n",
      "synthesis.b8.conv0.affine.weight\n",
      "synthesis.b8.conv0.affine.bias\n",
      "synthesis.b8.conv1.weight\n",
      "synthesis.b8.conv1.noise_strength\n",
      "synthesis.b8.conv1.bias\n",
      "synthesis.b8.conv1.affine.weight\n",
      "synthesis.b8.conv1.affine.bias\n",
      "synthesis.b8.torgb.weight\n",
      "synthesis.b8.torgb.bias\n",
      "synthesis.b8.torgb.affine.weight\n",
      "synthesis.b8.torgb.affine.bias\n",
      "synthesis.b8.toseg.weight\n",
      "synthesis.b8.toseg.bias\n",
      "synthesis.b8.toseg.affine.weight\n",
      "synthesis.b8.toseg.affine.bias\n",
      "synthesis.b16.conv0.weight\n",
      "synthesis.b16.conv0.noise_strength\n",
      "synthesis.b16.conv0.bias\n",
      "synthesis.b16.conv0.affine.weight\n",
      "synthesis.b16.conv0.affine.bias\n",
      "synthesis.b16.conv1.weight\n",
      "synthesis.b16.conv1.noise_strength\n",
      "synthesis.b16.conv1.bias\n",
      "synthesis.b16.conv1.affine.weight\n",
      "synthesis.b16.conv1.affine.bias\n",
      "synthesis.b16.torgb.weight\n",
      "synthesis.b16.torgb.bias\n",
      "synthesis.b16.torgb.affine.weight\n",
      "synthesis.b16.torgb.affine.bias\n",
      "synthesis.b16.toseg.weight\n",
      "synthesis.b16.toseg.bias\n",
      "synthesis.b16.toseg.affine.weight\n",
      "synthesis.b16.toseg.affine.bias\n",
      "synthesis.b32.conv0.weight\n",
      "synthesis.b32.conv0.noise_strength\n",
      "synthesis.b32.conv0.bias\n",
      "synthesis.b32.conv0.affine.weight\n",
      "synthesis.b32.conv0.affine.bias\n",
      "synthesis.b32.conv1.weight\n",
      "synthesis.b32.conv1.noise_strength\n",
      "synthesis.b32.conv1.bias\n",
      "synthesis.b32.conv1.affine.weight\n",
      "synthesis.b32.conv1.affine.bias\n",
      "synthesis.b32.torgb.weight\n",
      "synthesis.b32.torgb.bias\n",
      "synthesis.b32.torgb.affine.weight\n",
      "synthesis.b32.torgb.affine.bias\n",
      "synthesis.b32.toseg.weight\n",
      "synthesis.b32.toseg.bias\n",
      "synthesis.b32.toseg.affine.weight\n",
      "synthesis.b32.toseg.affine.bias\n",
      "synthesis.b64.conv0.weight\n",
      "synthesis.b64.conv0.noise_strength\n",
      "synthesis.b64.conv0.bias\n",
      "synthesis.b64.conv0.affine.weight\n",
      "synthesis.b64.conv0.affine.bias\n",
      "synthesis.b64.conv1.weight\n",
      "synthesis.b64.conv1.noise_strength\n",
      "synthesis.b64.conv1.bias\n",
      "synthesis.b64.conv1.affine.weight\n",
      "synthesis.b64.conv1.affine.bias\n",
      "synthesis.b64.torgb.weight\n",
      "synthesis.b64.torgb.bias\n",
      "synthesis.b64.torgb.affine.weight\n",
      "synthesis.b64.torgb.affine.bias\n",
      "synthesis.b64.toseg.weight\n",
      "synthesis.b64.toseg.bias\n",
      "synthesis.b64.toseg.affine.weight\n",
      "synthesis.b64.toseg.affine.bias\n",
      "synthesis.b128.conv0.weight\n",
      "synthesis.b128.conv0.noise_strength\n",
      "synthesis.b128.conv0.bias\n",
      "synthesis.b128.conv0.affine.weight\n",
      "synthesis.b128.conv0.affine.bias\n",
      "synthesis.b128.conv1.weight\n",
      "synthesis.b128.conv1.noise_strength\n",
      "synthesis.b128.conv1.bias\n",
      "synthesis.b128.conv1.affine.weight\n",
      "synthesis.b128.conv1.affine.bias\n",
      "synthesis.b128.torgb.weight\n",
      "synthesis.b128.torgb.bias\n",
      "synthesis.b128.torgb.affine.weight\n",
      "synthesis.b128.torgb.affine.bias\n",
      "synthesis.b128.toseg.weight\n",
      "synthesis.b128.toseg.bias\n",
      "synthesis.b128.toseg.affine.weight\n",
      "synthesis.b128.toseg.affine.bias\n",
      "synthesis.b256.conv0.weight\n",
      "synthesis.b256.conv0.noise_strength\n",
      "synthesis.b256.conv0.bias\n",
      "synthesis.b256.conv0.affine.weight\n",
      "synthesis.b256.conv0.affine.bias\n",
      "synthesis.b256.conv1.weight\n",
      "synthesis.b256.conv1.noise_strength\n",
      "synthesis.b256.conv1.bias\n",
      "synthesis.b256.conv1.affine.weight\n",
      "synthesis.b256.conv1.affine.bias\n",
      "synthesis.b256.torgb.weight\n",
      "synthesis.b256.torgb.bias\n",
      "synthesis.b256.torgb.affine.weight\n",
      "synthesis.b256.torgb.affine.bias\n",
      "synthesis.b256.toseg.weight\n",
      "synthesis.b256.toseg.bias\n",
      "synthesis.b256.toseg.affine.weight\n",
      "synthesis.b256.toseg.affine.bias\n",
      "mapping.fc0.weight\n",
      "mapping.fc0.bias\n",
      "mapping.fc1.weight\n",
      "mapping.fc1.bias\n",
      "mapping.fc2.weight\n",
      "mapping.fc2.bias\n",
      "mapping.fc3.weight\n",
      "mapping.fc3.bias\n",
      "mapping.fc4.weight\n",
      "mapping.fc4.bias\n",
      "mapping.fc5.weight\n",
      "mapping.fc5.bias\n",
      "mapping.fc6.weight\n",
      "mapping.fc6.bias\n",
      "mapping.fc7.weight\n",
      "mapping.fc7.bias\n",
      "synthesis.b4.resample_filter\n",
      "synthesis.b4.conv1.resample_filter\n",
      "synthesis.b4.conv1.noise_const\n",
      "synthesis.b8.resample_filter\n",
      "synthesis.b8.conv0.resample_filter\n",
      "synthesis.b8.conv0.noise_const\n",
      "synthesis.b8.conv1.resample_filter\n",
      "synthesis.b8.conv1.noise_const\n",
      "synthesis.b16.resample_filter\n",
      "synthesis.b16.conv0.resample_filter\n",
      "synthesis.b16.conv0.noise_const\n",
      "synthesis.b16.conv1.resample_filter\n",
      "synthesis.b16.conv1.noise_const\n",
      "synthesis.b32.resample_filter\n",
      "synthesis.b32.conv0.resample_filter\n",
      "synthesis.b32.conv0.noise_const\n",
      "synthesis.b32.conv1.resample_filter\n",
      "synthesis.b32.conv1.noise_const\n",
      "synthesis.b64.resample_filter\n",
      "synthesis.b64.conv0.resample_filter\n",
      "synthesis.b64.conv0.noise_const\n",
      "synthesis.b64.conv1.resample_filter\n",
      "synthesis.b64.conv1.noise_const\n",
      "synthesis.b128.resample_filter\n",
      "synthesis.b128.conv0.resample_filter\n",
      "synthesis.b128.conv0.noise_const\n",
      "synthesis.b128.conv1.resample_filter\n",
      "synthesis.b128.conv1.noise_const\n",
      "synthesis.b256.resample_filter\n",
      "synthesis.b256.conv0.resample_filter\n",
      "synthesis.b256.conv0.noise_const\n",
      "synthesis.b256.conv1.resample_filter\n",
      "synthesis.b256.conv1.noise_const\n",
      "mapping.w_avg\n",
      "======\n",
      "---- Parallel\n",
      "---- Create Upsamplers\n",
      "---- Done\n",
      "-- Get latent info\n",
      "latent all: torch.Size([8, 512])\n",
      "-- load mask\n",
      "============================================================\n",
      "Go over latents\n",
      "-- clean up masks\n",
      "-- Generate all training data for pixel classifer\n",
      "Len latent all: 2\n",
      "all_feature_maps TRAIN:  (131072, 4992)\n",
      "Show training examples\n",
      "Latent input size: torch.Size([512]) torch.Size([1, 512])\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "Feature maps from (latent to image): torch.Size([1, 4992, 256, 256])\n",
      "Permute: torch.Size([1, 256, 256, 4992])\n",
      "reshape: torch.Size([65536, 4992])\n",
      "<PIL.Image.Image image mode=RGB size=256x256 at 0x7F72AD272D60>\n",
      "<PIL.Image.Image image mode=RGB size=256x256 at 0x7F72AAF30610>\n",
      "[[[194 117  97]\n",
      "  [197 120 100]\n",
      "  [202 125 105]\n",
      "  ...\n",
      "  [158  93  87]\n",
      "  [154  89  85]\n",
      "  [148  83  79]]\n",
      "\n",
      " [[200 123 103]\n",
      "  [203 126 106]\n",
      "  [207 130 110]\n",
      "  ...\n",
      "  [160  95  89]\n",
      "  [156  91  87]\n",
      "  [149  84  80]]\n",
      "\n",
      " [[208 132 109]\n",
      "  [210 134 111]\n",
      "  [212 136 113]\n",
      "  ...\n",
      "  [161  97  88]\n",
      "  [156  91  85]\n",
      "  [148  83  77]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[208 127 123]\n",
      "  [211 130 126]\n",
      "  [216 135 131]\n",
      "  ...\n",
      "  [251 164 144]\n",
      "  [247 160 141]\n",
      "  [240 153 134]]\n",
      "\n",
      " [[203 122 119]\n",
      "  [206 125 122]\n",
      "  [211 130 127]\n",
      "  ...\n",
      "  [255 168 148]\n",
      "  [251 164 145]\n",
      "  [244 157 138]]\n",
      "\n",
      " [[197 116 113]\n",
      "  [200 119 116]\n",
      "  [205 124 121]\n",
      "  ...\n",
      "  [250 163 143]\n",
      "  [247 160 141]\n",
      "  [239 152 133]]]\n",
      "<PIL.Image.Image image mode=RGB size=256x256 at 0x7F72AD272D60>\n",
      "Latent input size: torch.Size([512]) torch.Size([1, 512])\n",
      "Feature maps from (latent to image): torch.Size([1, 4992, 256, 256])\n",
      "Permute: torch.Size([1, 256, 256, 4992])\n",
      "reshape: torch.Size([65536, 4992])\n",
      "<PIL.Image.Image image mode=RGB size=256x256 at 0x7F72AD272D60>\n",
      "<PIL.Image.Image image mode=RGB size=256x256 at 0x7F72AAF30610>\n",
      "[[[172 100  78]\n",
      "  [174 102  80]\n",
      "  [177 105  83]\n",
      "  ...\n",
      "  [124  69  64]\n",
      "  [124  69  64]\n",
      "  [120  65  60]]\n",
      "\n",
      " [[174 102  80]\n",
      "  [176 104  82]\n",
      "  [179 107  85]\n",
      "  ...\n",
      "  [116  61  56]\n",
      "  [116  61  56]\n",
      "  [112  57  52]]\n",
      "\n",
      " [[177 105  83]\n",
      "  [179 107  85]\n",
      "  [181 109  87]\n",
      "  ...\n",
      "  [117  59  55]\n",
      "  [116  58  54]\n",
      "  [111  53  49]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[175 102  93]\n",
      "  [178 105  96]\n",
      "  [180 107  98]\n",
      "  ...\n",
      "  [215 123 102]\n",
      "  [216 124 103]\n",
      "  [215 123 102]]\n",
      "\n",
      " [[172  99  90]\n",
      "  [174 101  92]\n",
      "  [176 103  94]\n",
      "  ...\n",
      "  [217 125 104]\n",
      "  [219 127 106]\n",
      "  [219 127 106]]\n",
      "\n",
      " [[169  96  87]\n",
      "  [171  98  89]\n",
      "  [173 100  91]\n",
      "  ...\n",
      "  [221 129 108]\n",
      "  [225 133 112]\n",
      "  [227 135 114]]]\n",
      "<PIL.Image.Image image mode=RGB size=256x256 at 0x7F72AD272D60>\n",
      "FINAL all_feature_maps_train (131072, 4992)\n",
      "-- Done\n",
      " *********************** max_label 3 ***********************\n",
      " *********************** Current number data 2 ***********************\n",
      " *********************** Current dataloader length 2048 ***********************\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]Epoch :  0 iteration 1000 loss 0.029974771663546562 acc tensor(98.4375, device='cuda:0')\n",
      "Epoch :  0 iteration 2000 loss 0.03791302442550659 acc tensor(98.4375, device='cuda:0')\n",
      "  1%|▍                                          | 1/100 [00:04<07:13,  4.38s/it]Epoch :  1 iteration 3000 loss 0.01434347778558731 acc tensor(100., device='cuda:0')\n",
      "Epoch :  1 iteration 4000 loss 0.0008859147783368826 acc tensor(100., device='cuda:0')\n",
      "  2%|▊                                          | 2/100 [00:08<07:06,  4.35s/it]Epoch :  2 iteration 5000 loss 0.025200698524713516 acc tensor(98.4375, device='cuda:0')\n",
      "Save checkpoint, Epoch :  2  Path:  IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/models/model_20parts_iter5000_number_0.pth\n",
      "Epoch :  2 iteration 6000 loss 0.030872825533151627 acc tensor(98.4375, device='cuda:0')\n",
      "  3%|█▎                                         | 3/100 [00:12<07:00,  4.33s/it]Epoch :  3 iteration 7000 loss 0.0027009586337953806 acc tensor(100., device='cuda:0')\n",
      "Epoch :  3 iteration 8000 loss 0.005302120000123978 acc tensor(100., device='cuda:0')\n",
      "  4%|█▋                                         | 4/100 [00:17<06:53,  4.31s/it]*************** Break, Total iters, 8244 , at epoch 4 ***************\n",
      "  4%|█▋                                         | 4/100 [00:17<06:55,  4.33s/it]\n",
      "save to: IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/models/model_0.pth\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]Epoch :  0 iteration 1000 loss 0.018033985048532486 acc tensor(98.4375, device='cuda:0')\n",
      "Epoch :  0 iteration 2000 loss 0.039593394845724106 acc tensor(98.4375, device='cuda:0')\n",
      "  1%|▍                                          | 1/100 [00:04<08:07,  4.92s/it]Epoch :  1 iteration 3000 loss 0.0010334644466638565 acc tensor(100., device='cuda:0')\n",
      "Epoch :  1 iteration 4000 loss 0.0031423114705830812 acc tensor(100., device='cuda:0')\n",
      "  2%|▊                                          | 2/100 [00:09<07:50,  4.80s/it]Epoch :  2 iteration 5000 loss 0.03411728888750076 acc tensor(96.8750, device='cuda:0')\n",
      "Save checkpoint, Epoch :  2  Path:  IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/models/model_20parts_iter5000_number_1.pth\n",
      "Epoch :  2 iteration 6000 loss 0.025882869958877563 acc tensor(98.4375, device='cuda:0')\n",
      "  3%|█▎                                         | 3/100 [00:13<07:35,  4.70s/it]Epoch :  3 iteration 7000 loss 0.04275652393698692 acc tensor(98.4375, device='cuda:0')\n",
      "Epoch :  3 iteration 8000 loss 0.010570120997726917 acc tensor(100., device='cuda:0')\n",
      "  4%|█▋                                         | 4/100 [00:18<07:28,  4.67s/it]*************** Break, Total iters, 8273 , at epoch 4 ***************\n",
      "  4%|█▋                                         | 4/100 [00:18<07:28,  4.67s/it]\n",
      "save to: IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/models/model_1.pth\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]Epoch :  0 iteration 1000 loss 0.010851334780454636 acc tensor(100., device='cuda:0')\n",
      "Epoch :  0 iteration 2000 loss 0.010707274079322815 acc tensor(100., device='cuda:0')\n",
      "  1%|▍                                          | 1/100 [00:04<07:08,  4.33s/it]Epoch :  1 iteration 3000 loss 0.029752135276794434 acc tensor(98.4375, device='cuda:0')\n",
      "Epoch :  1 iteration 4000 loss 0.022067682817578316 acc tensor(98.4375, device='cuda:0')\n",
      "  2%|▊                                          | 2/100 [00:08<07:04,  4.33s/it]Epoch :  2 iteration 5000 loss 0.0007807731744833291 acc tensor(100., device='cuda:0')\n",
      "Save checkpoint, Epoch :  2  Path:  IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/models/model_20parts_iter5000_number_2.pth\n",
      "Epoch :  2 iteration 6000 loss 0.0007286955369636416 acc tensor(100., device='cuda:0')\n",
      "  3%|█▎                                         | 3/100 [00:12<06:59,  4.33s/it]Epoch :  3 iteration 7000 loss 0.03985769301652908 acc tensor(98.4375, device='cuda:0')\n",
      "Epoch :  3 iteration 8000 loss 0.0052739898674190044 acc tensor(100., device='cuda:0')\n",
      "  4%|█▋                                         | 4/100 [00:17<06:56,  4.34s/it]*************** Break, Total iters, 8298 , at epoch 4 ***************\n",
      "  4%|█▋                                         | 4/100 [00:17<07:01,  4.39s/it]\n",
      "save to: IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/models/model_2.pth\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]Epoch :  0 iteration 1000 loss 0.02124100737273693 acc tensor(98.4375, device='cuda:0')\n",
      "Epoch :  0 iteration 2000 loss 0.00993344560265541 acc tensor(100., device='cuda:0')\n",
      "  1%|▍                                          | 1/100 [00:04<07:57,  4.82s/it]Epoch :  1 iteration 3000 loss 0.005534827709197998 acc tensor(100., device='cuda:0')\n",
      "Epoch :  1 iteration 4000 loss 0.03458598628640175 acc tensor(96.8750, device='cuda:0')\n",
      "  2%|▊                                          | 2/100 [00:09<07:44,  4.74s/it]Epoch :  2 iteration 5000 loss 0.03205741569399834 acc tensor(100., device='cuda:0')\n",
      "Save checkpoint, Epoch :  2  Path:  IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/models/model_20parts_iter5000_number_3.pth\n",
      "Epoch :  2 iteration 6000 loss 0.05818581581115723 acc tensor(95.3125, device='cuda:0')\n",
      "  3%|█▎                                         | 3/100 [00:13<07:28,  4.62s/it]Epoch :  3 iteration 7000 loss 0.06673575192689896 acc tensor(96.8750, device='cuda:0')\n",
      "Epoch :  3 iteration 8000 loss 0.11830653250217438 acc tensor(96.8750, device='cuda:0')\n",
      "  4%|█▋                                         | 4/100 [00:18<07:19,  4.58s/it]*************** Break, Total iters, 8301 , at epoch 4 ***************\n",
      "  4%|█▋                                         | 4/100 [00:18<07:22,  4.61s/it]\n",
      "save to: IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/models/model_3.pth\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]Epoch :  0 iteration 1000 loss 0.03099437616765499 acc tensor(100., device='cuda:0')\n",
      "Epoch :  0 iteration 2000 loss 0.043600454926490784 acc tensor(98.4375, device='cuda:0')\n",
      "  1%|▍                                          | 1/100 [00:04<07:10,  4.35s/it]Epoch :  1 iteration 3000 loss 0.022708294913172722 acc tensor(98.4375, device='cuda:0')\n",
      "Epoch :  1 iteration 4000 loss 0.004293364472687244 acc tensor(100., device='cuda:0')\n",
      "  2%|▊                                          | 2/100 [00:08<07:03,  4.32s/it]Epoch :  2 iteration 5000 loss 0.12677106261253357 acc tensor(95.3125, device='cuda:0')\n",
      "Save checkpoint, Epoch :  2  Path:  IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/models/model_20parts_iter5000_number_4.pth\n",
      "Epoch :  2 iteration 6000 loss 0.008720558136701584 acc tensor(100., device='cuda:0')\n",
      "  3%|█▎                                         | 3/100 [00:12<06:55,  4.29s/it]Epoch :  3 iteration 7000 loss 0.04993119835853577 acc tensor(98.4375, device='cuda:0')\n",
      "Epoch :  3 iteration 8000 loss 0.05127660930156708 acc tensor(98.4375, device='cuda:0')\n",
      "  4%|█▋                                         | 4/100 [00:17<06:51,  4.29s/it]*************** Break, Total iters, 8270 , at epoch 4 ***************\n",
      "  4%|█▋                                         | 4/100 [00:17<06:54,  4.32s/it]\n",
      "save to: IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/models/model_4.pth\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]Epoch :  0 iteration 1000 loss 0.018552372232079506 acc tensor(100., device='cuda:0')\n",
      "Epoch :  0 iteration 2000 loss 0.019318385049700737 acc tensor(98.4375, device='cuda:0')\n",
      "  1%|▍                                          | 1/100 [00:04<07:52,  4.78s/it]Epoch :  1 iteration 3000 loss 0.03422970324754715 acc tensor(98.4375, device='cuda:0')\n",
      "Epoch :  1 iteration 4000 loss 0.07590268552303314 acc tensor(96.8750, device='cuda:0')\n",
      "  2%|▊                                          | 2/100 [00:09<07:37,  4.67s/it]Epoch :  2 iteration 5000 loss 0.0007059185882098973 acc tensor(100., device='cuda:0')\n",
      "Save checkpoint, Epoch :  2  Path:  IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/models/model_20parts_iter5000_number_5.pth\n",
      "Epoch :  2 iteration 6000 loss 0.006392019800841808 acc tensor(100., device='cuda:0')\n",
      "  3%|█▎                                         | 3/100 [00:13<07:22,  4.57s/it]Epoch :  3 iteration 7000 loss 0.0037899089511483908 acc tensor(100., device='cuda:0')\n",
      "Epoch :  3 iteration 8000 loss 0.005326672922819853 acc tensor(100., device='cuda:0')\n",
      "  4%|█▋                                         | 4/100 [00:17<07:13,  4.51s/it]*************** Break, Total iters, 8295 , at epoch 4 ***************\n",
      "  4%|█▋                                         | 4/100 [00:18<07:15,  4.53s/it]\n",
      "save to: IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/models/model_5.pth\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]Epoch :  0 iteration 1000 loss 0.024800240993499756 acc tensor(100., device='cuda:0')\n",
      "Epoch :  0 iteration 2000 loss 0.03139812499284744 acc tensor(96.8750, device='cuda:0')\n",
      "  1%|▍                                          | 1/100 [00:04<07:11,  4.36s/it]Epoch :  1 iteration 3000 loss 0.0019784471951425076 acc tensor(100., device='cuda:0')\n",
      "Epoch :  1 iteration 4000 loss 0.041380852460861206 acc tensor(96.8750, device='cuda:0')\n",
      "  2%|▊                                          | 2/100 [00:08<07:08,  4.37s/it]Epoch :  2 iteration 5000 loss 0.004956440068781376 acc tensor(100., device='cuda:0')\n",
      "Save checkpoint, Epoch :  2  Path:  IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/models/model_20parts_iter5000_number_6.pth\n",
      "Epoch :  2 iteration 6000 loss 0.03336288034915924 acc tensor(98.4375, device='cuda:0')\n",
      "  3%|█▎                                         | 3/100 [00:13<07:02,  4.36s/it]Epoch :  3 iteration 7000 loss 0.029219694435596466 acc tensor(98.4375, device='cuda:0')\n",
      "Epoch :  3 iteration 8000 loss 0.0024378281086683273 acc tensor(100., device='cuda:0')\n",
      "  4%|█▋                                         | 4/100 [00:17<06:56,  4.34s/it]*************** Break, Total iters, 8252 , at epoch 4 ***************\n",
      "  4%|█▋                                         | 4/100 [00:17<07:00,  4.38s/it]\n",
      "save to: IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/models/model_6.pth\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]Epoch :  0 iteration 1000 loss 0.012980838306248188 acc tensor(100., device='cuda:0')\n",
      "Epoch :  0 iteration 2000 loss 0.006202641408890486 acc tensor(100., device='cuda:0')\n",
      "  1%|▍                                          | 1/100 [00:04<07:56,  4.82s/it]Epoch :  1 iteration 3000 loss 0.020716385915875435 acc tensor(100., device='cuda:0')\n",
      "Epoch :  1 iteration 4000 loss 0.0014030063757672906 acc tensor(100., device='cuda:0')\n",
      "  2%|▊                                          | 2/100 [00:09<07:41,  4.70s/it]Epoch :  2 iteration 5000 loss 0.014561428688466549 acc tensor(98.4375, device='cuda:0')\n",
      "Save checkpoint, Epoch :  2  Path:  IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/models/model_20parts_iter5000_number_7.pth\n",
      "Epoch :  2 iteration 6000 loss 0.024639366194605827 acc tensor(98.4375, device='cuda:0')\n",
      "  3%|█▎                                         | 3/100 [00:13<07:25,  4.60s/it]Epoch :  3 iteration 7000 loss 0.0038014971651136875 acc tensor(100., device='cuda:0')\n",
      "Epoch :  3 iteration 8000 loss 0.0015483079478144646 acc tensor(100., device='cuda:0')\n",
      "  4%|█▋                                         | 4/100 [00:18<07:20,  4.59s/it]*************** Break, Total iters, 8250 , at epoch 4 ***************\n",
      "  4%|█▋                                         | 4/100 [00:18<07:19,  4.58s/it]\n",
      "save to: IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/models/model_7.pth\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]Epoch :  0 iteration 1000 loss 0.05316866189241409 acc tensor(96.8750, device='cuda:0')\n",
      "Epoch :  0 iteration 2000 loss 0.00275201047770679 acc tensor(100., device='cuda:0')\n",
      "  1%|▍                                          | 1/100 [00:04<07:03,  4.28s/it]Epoch :  1 iteration 3000 loss 0.0843992829322815 acc tensor(96.8750, device='cuda:0')\n",
      "Epoch :  1 iteration 4000 loss 0.008802722208201885 acc tensor(100., device='cuda:0')\n",
      "  2%|▊                                          | 2/100 [00:08<06:57,  4.26s/it]Epoch :  2 iteration 5000 loss 0.00043606225517578423 acc tensor(100., device='cuda:0')\n",
      "Save checkpoint, Epoch :  2  Path:  IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/models/model_20parts_iter5000_number_8.pth\n",
      "Epoch :  2 iteration 6000 loss 0.009005087427794933 acc tensor(100., device='cuda:0')\n",
      "  3%|█▎                                         | 3/100 [00:12<06:53,  4.26s/it]Epoch :  3 iteration 7000 loss 0.0012514939298853278 acc tensor(100., device='cuda:0')\n",
      "Epoch :  3 iteration 8000 loss 0.01661660335958004 acc tensor(98.4375, device='cuda:0')\n",
      "  4%|█▋                                         | 4/100 [00:17<06:48,  4.26s/it]*************** Break, Total iters, 8303 , at epoch 4 ***************\n",
      "  4%|█▋                                         | 4/100 [00:17<06:53,  4.31s/it]\n",
      "save to: IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/models/model_8.pth\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]Epoch :  0 iteration 1000 loss 0.04356776550412178 acc tensor(96.8750, device='cuda:0')\n",
      "Epoch :  0 iteration 2000 loss 0.02785811759531498 acc tensor(98.4375, device='cuda:0')\n",
      "  1%|▍                                          | 1/100 [00:04<07:53,  4.78s/it]Epoch :  1 iteration 3000 loss 0.009589744731783867 acc tensor(100., device='cuda:0')\n",
      "Epoch :  1 iteration 4000 loss 0.038238123059272766 acc tensor(98.4375, device='cuda:0')\n",
      "  2%|▊                                          | 2/100 [00:09<07:39,  4.68s/it]Epoch :  2 iteration 5000 loss 0.012615996412932873 acc tensor(100., device='cuda:0')\n",
      "Save checkpoint, Epoch :  2  Path:  IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/models/model_20parts_iter5000_number_9.pth\n",
      "Epoch :  2 iteration 6000 loss 0.0037266183644533157 acc tensor(100., device='cuda:0')\n",
      "  3%|█▎                                         | 3/100 [00:13<07:23,  4.58s/it]Epoch :  3 iteration 7000 loss 0.0630025565624237 acc tensor(98.4375, device='cuda:0')\n",
      "Epoch :  3 iteration 8000 loss 0.04277297854423523 acc tensor(98.4375, device='cuda:0')\n",
      "  4%|█▋                                         | 4/100 [00:18<07:15,  4.54s/it]*************** Break, Total iters, 8273 , at epoch 4 ***************\n",
      "  4%|█▋                                         | 4/100 [00:18<07:16,  4.55s/it]\n",
      "save to: IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/models/model_9.pth\n"
     ]
    }
   ],
   "source": [
    "exp_interpreter = exp + \"/train_datagan.json\" \n",
    "!bash docker_run.sh python train_interpreter_DB_SG2.py --exp $exp_interpreter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Data (RGB, NIR, MASK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "Opt {'exp_dir': 'IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2', 'batch_size': 64, 'category': 'eyes_256', 'debug': False, 'dim': [256, 256, 4992], 'deeplab_res': 256, 'number_class': 4, 'testing_data_number_class': 4, 'max_training': 2, 'stylegan_ver': '2', 'annotation_data_from_w': False, 'annotation_mask_path': 'eyes_processed', 'testing_path': '', 'average_latent': 'avg_latent_stylegan.npy', 'annotation_image_latent_path': 'latent_stylegan.npy', 'stylegan_checkpoint': 'IJCB_EXPERIMENTS/checkpoints/IJCB_2022_checkpoints/CrossEyed_NIR_RGB_NEW_001120.pkl', 'model_num': 10, 'upsample_mode': 'bilinear', 'upsample_threshold': '8'}\n",
      "cp: 'IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/train_datagan.json' and 'IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/train_datagan.json' are the same file\n",
      "Generate data\n",
      "Experiment folder created at: IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/samples_5000\n",
      "Eyes category\n",
      "---- Resolution: 256  Layers: 7\n",
      "---- Get avg latent\n",
      "---- Latent to torch\n",
      "AVG latent torch.Size([14, 512])\n",
      "----  Build Generator\n",
      "Resuming from \"IJCB_EXPERIMENTS/checkpoints/IJCB_2022_checkpoints/CrossEyed_NIR_RGB_NEW_001120.pkl\"\n",
      "Prepare StytleGAN2\n",
      "{'ref_gpus': 1, 'kimg': 25000, 'mb': -1, 'mbstd': -1, 'fmaps': -1, 'lrate': -1, 'gamma': -1, 'ema': -1, 'ramp': 0.05, 'map': 8}\n",
      "{'class_name': 'training_scripts_DB_SG2.networks.Generator', 'z_dim': 512, 'w_dim': 512, 'mapping_kwargs': {'num_layers': 8}, 'synthesis_kwargs': {'save_intermediate_results': True, 'channel_base': 16384, 'channel_max': 512, 'num_fp16_res': 4, 'conv_clamp': 256}}\n",
      "{'c_dim': 0, 'img_resolution': 256, 'img_channels': 3}\n",
      "Synthesis network:\n",
      "- Block resolutions: [4, 8, 16, 32, 64, 128, 256]\n",
      "- Channels dict: {4: 512, 8: 512, 16: 512, 32: 512, 64: 256, 128: 128, 256: 64}\n",
      "Generator(\n",
      "  (synthesis): SynthesisNetwork(\n",
      "    (b4): SynthesisBlock(\n",
      "      (conv1): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (torgb): ToRGBLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (toseg): ToSEGLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "    )\n",
      "    (b8): SynthesisBlock(\n",
      "      (conv0): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (conv1): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (torgb): ToRGBLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (toseg): ToSEGLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "    )\n",
      "    (b16): SynthesisBlock(\n",
      "      (conv0): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (conv1): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (torgb): ToRGBLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (toseg): ToSEGLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "    )\n",
      "    (b32): SynthesisBlock(\n",
      "      (conv0): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (conv1): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (torgb): ToRGBLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (toseg): ToSEGLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "    )\n",
      "    (b64): SynthesisBlock(\n",
      "      (conv0): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (conv1): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (torgb): ToRGBLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (toseg): ToSEGLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "    )\n",
      "    (b128): SynthesisBlock(\n",
      "      (conv0): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (conv1): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (torgb): ToRGBLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (toseg): ToSEGLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "    )\n",
      "    (b256): SynthesisBlock(\n",
      "      (conv0): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (conv1): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (torgb): ToRGBLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (toseg): ToSEGLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mapping): MappingNetwork(\n",
      "    (fc0): FullyConnectedLayer()\n",
      "    (fc1): FullyConnectedLayer()\n",
      "    (fc2): FullyConnectedLayer()\n",
      "    (fc3): FullyConnectedLayer()\n",
      "    (fc4): FullyConnectedLayer()\n",
      "    (fc5): FullyConnectedLayer()\n",
      "    (fc6): FullyConnectedLayer()\n",
      "    (fc7): FullyConnectedLayer()\n",
      "  )\n",
      ")\n",
      "Resuming from \"IJCB_EXPERIMENTS/checkpoints/IJCB_2022_checkpoints/CrossEyed_NIR_RGB_NEW_001120.pkl\"\n",
      "synthesis.b4.const\n",
      "synthesis.b4.conv1.weight\n",
      "synthesis.b4.conv1.noise_strength\n",
      "synthesis.b4.conv1.bias\n",
      "synthesis.b4.conv1.affine.weight\n",
      "synthesis.b4.conv1.affine.bias\n",
      "synthesis.b4.torgb.weight\n",
      "synthesis.b4.torgb.bias\n",
      "synthesis.b4.torgb.affine.weight\n",
      "synthesis.b4.torgb.affine.bias\n",
      "synthesis.b4.toseg.weight\n",
      "synthesis.b4.toseg.bias\n",
      "synthesis.b4.toseg.affine.weight\n",
      "synthesis.b4.toseg.affine.bias\n",
      "synthesis.b8.conv0.weight\n",
      "synthesis.b8.conv0.noise_strength\n",
      "synthesis.b8.conv0.bias\n",
      "synthesis.b8.conv0.affine.weight\n",
      "synthesis.b8.conv0.affine.bias\n",
      "synthesis.b8.conv1.weight\n",
      "synthesis.b8.conv1.noise_strength\n",
      "synthesis.b8.conv1.bias\n",
      "synthesis.b8.conv1.affine.weight\n",
      "synthesis.b8.conv1.affine.bias\n",
      "synthesis.b8.torgb.weight\n",
      "synthesis.b8.torgb.bias\n",
      "synthesis.b8.torgb.affine.weight\n",
      "synthesis.b8.torgb.affine.bias\n",
      "synthesis.b8.toseg.weight\n",
      "synthesis.b8.toseg.bias\n",
      "synthesis.b8.toseg.affine.weight\n",
      "synthesis.b8.toseg.affine.bias\n",
      "synthesis.b16.conv0.weight\n",
      "synthesis.b16.conv0.noise_strength\n",
      "synthesis.b16.conv0.bias\n",
      "synthesis.b16.conv0.affine.weight\n",
      "synthesis.b16.conv0.affine.bias\n",
      "synthesis.b16.conv1.weight\n",
      "synthesis.b16.conv1.noise_strength\n",
      "synthesis.b16.conv1.bias\n",
      "synthesis.b16.conv1.affine.weight\n",
      "synthesis.b16.conv1.affine.bias\n",
      "synthesis.b16.torgb.weight\n",
      "synthesis.b16.torgb.bias\n",
      "synthesis.b16.torgb.affine.weight\n",
      "synthesis.b16.torgb.affine.bias\n",
      "synthesis.b16.toseg.weight\n",
      "synthesis.b16.toseg.bias\n",
      "synthesis.b16.toseg.affine.weight\n",
      "synthesis.b16.toseg.affine.bias\n",
      "synthesis.b32.conv0.weight\n",
      "synthesis.b32.conv0.noise_strength\n",
      "synthesis.b32.conv0.bias\n",
      "synthesis.b32.conv0.affine.weight\n",
      "synthesis.b32.conv0.affine.bias\n",
      "synthesis.b32.conv1.weight\n",
      "synthesis.b32.conv1.noise_strength\n",
      "synthesis.b32.conv1.bias\n",
      "synthesis.b32.conv1.affine.weight\n",
      "synthesis.b32.conv1.affine.bias\n",
      "synthesis.b32.torgb.weight\n",
      "synthesis.b32.torgb.bias\n",
      "synthesis.b32.torgb.affine.weight\n",
      "synthesis.b32.torgb.affine.bias\n",
      "synthesis.b32.toseg.weight\n",
      "synthesis.b32.toseg.bias\n",
      "synthesis.b32.toseg.affine.weight\n",
      "synthesis.b32.toseg.affine.bias\n",
      "synthesis.b64.conv0.weight\n",
      "synthesis.b64.conv0.noise_strength\n",
      "synthesis.b64.conv0.bias\n",
      "synthesis.b64.conv0.affine.weight\n",
      "synthesis.b64.conv0.affine.bias\n",
      "synthesis.b64.conv1.weight\n",
      "synthesis.b64.conv1.noise_strength\n",
      "synthesis.b64.conv1.bias\n",
      "synthesis.b64.conv1.affine.weight\n",
      "synthesis.b64.conv1.affine.bias\n",
      "synthesis.b64.torgb.weight\n",
      "synthesis.b64.torgb.bias\n",
      "synthesis.b64.torgb.affine.weight\n",
      "synthesis.b64.torgb.affine.bias\n",
      "synthesis.b64.toseg.weight\n",
      "synthesis.b64.toseg.bias\n",
      "synthesis.b64.toseg.affine.weight\n",
      "synthesis.b64.toseg.affine.bias\n",
      "synthesis.b128.conv0.weight\n",
      "synthesis.b128.conv0.noise_strength\n",
      "synthesis.b128.conv0.bias\n",
      "synthesis.b128.conv0.affine.weight\n",
      "synthesis.b128.conv0.affine.bias\n",
      "synthesis.b128.conv1.weight\n",
      "synthesis.b128.conv1.noise_strength\n",
      "synthesis.b128.conv1.bias\n",
      "synthesis.b128.conv1.affine.weight\n",
      "synthesis.b128.conv1.affine.bias\n",
      "synthesis.b128.torgb.weight\n",
      "synthesis.b128.torgb.bias\n",
      "synthesis.b128.torgb.affine.weight\n",
      "synthesis.b128.torgb.affine.bias\n",
      "synthesis.b128.toseg.weight\n",
      "synthesis.b128.toseg.bias\n",
      "synthesis.b128.toseg.affine.weight\n",
      "synthesis.b128.toseg.affine.bias\n",
      "synthesis.b256.conv0.weight\n",
      "synthesis.b256.conv0.noise_strength\n",
      "synthesis.b256.conv0.bias\n",
      "synthesis.b256.conv0.affine.weight\n",
      "synthesis.b256.conv0.affine.bias\n",
      "synthesis.b256.conv1.weight\n",
      "synthesis.b256.conv1.noise_strength\n",
      "synthesis.b256.conv1.bias\n",
      "synthesis.b256.conv1.affine.weight\n",
      "synthesis.b256.conv1.affine.bias\n",
      "synthesis.b256.torgb.weight\n",
      "synthesis.b256.torgb.bias\n",
      "synthesis.b256.torgb.affine.weight\n",
      "synthesis.b256.torgb.affine.bias\n",
      "synthesis.b256.toseg.weight\n",
      "synthesis.b256.toseg.bias\n",
      "synthesis.b256.toseg.affine.weight\n",
      "synthesis.b256.toseg.affine.bias\n",
      "mapping.fc0.weight\n",
      "mapping.fc0.bias\n",
      "mapping.fc1.weight\n",
      "mapping.fc1.bias\n",
      "mapping.fc2.weight\n",
      "mapping.fc2.bias\n",
      "mapping.fc3.weight\n",
      "mapping.fc3.bias\n",
      "mapping.fc4.weight\n",
      "mapping.fc4.bias\n",
      "mapping.fc5.weight\n",
      "mapping.fc5.bias\n",
      "mapping.fc6.weight\n",
      "mapping.fc6.bias\n",
      "mapping.fc7.weight\n",
      "mapping.fc7.bias\n",
      "synthesis.b4.resample_filter\n",
      "synthesis.b4.conv1.resample_filter\n",
      "synthesis.b4.conv1.noise_const\n",
      "synthesis.b8.resample_filter\n",
      "synthesis.b8.conv0.resample_filter\n",
      "synthesis.b8.conv0.noise_const\n",
      "synthesis.b8.conv1.resample_filter\n",
      "synthesis.b8.conv1.noise_const\n",
      "synthesis.b16.resample_filter\n",
      "synthesis.b16.conv0.resample_filter\n",
      "synthesis.b16.conv0.noise_const\n",
      "synthesis.b16.conv1.resample_filter\n",
      "synthesis.b16.conv1.noise_const\n",
      "synthesis.b32.resample_filter\n",
      "synthesis.b32.conv0.resample_filter\n",
      "synthesis.b32.conv0.noise_const\n",
      "synthesis.b32.conv1.resample_filter\n",
      "synthesis.b32.conv1.noise_const\n",
      "synthesis.b64.resample_filter\n",
      "synthesis.b64.conv0.resample_filter\n",
      "synthesis.b64.conv0.noise_const\n",
      "synthesis.b64.conv1.resample_filter\n",
      "synthesis.b64.conv1.noise_const\n",
      "synthesis.b128.resample_filter\n",
      "synthesis.b128.conv0.resample_filter\n",
      "synthesis.b128.conv0.noise_const\n",
      "synthesis.b128.conv1.resample_filter\n",
      "synthesis.b128.conv1.noise_const\n",
      "synthesis.b256.resample_filter\n",
      "synthesis.b256.conv0.resample_filter\n",
      "synthesis.b256.conv0.noise_const\n",
      "synthesis.b256.conv1.resample_filter\n",
      "synthesis.b256.conv1.noise_const\n",
      "mapping.w_avg\n",
      "======\n",
      "---- Parallel\n",
      "---- Create Upsamplers\n",
      "---- Done\n",
      "MODEL_NUMBER 0\n",
      "IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/models/model_0.pth\n",
      "MODEL_NUMBER 1\n",
      "IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/models/model_1.pth\n",
      "MODEL_NUMBER 2\n",
      "IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/models/model_2.pth\n",
      "MODEL_NUMBER 3\n",
      "IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/models/model_3.pth\n",
      "MODEL_NUMBER 4\n",
      "IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/models/model_4.pth\n",
      "MODEL_NUMBER 5\n",
      "IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/models/model_5.pth\n",
      "MODEL_NUMBER 6\n",
      "IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/models/model_6.pth\n",
      "MODEL_NUMBER 7\n",
      "IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/models/model_7.pth\n",
      "MODEL_NUMBER 8\n",
      "IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/models/model_8.pth\n",
      "MODEL_NUMBER 9\n",
      "IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2/models/model_9.pth\n",
      "num_sample:  5000\n",
      "  0%|                                                  | 0/5000 [00:00<?, ?it/s]Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "100%|█████████████████████████████████████| 5000/5000 [1:48:25<00:00,  1.30s/it]\n",
      "Run times:\n",
      "85.89 \\pm 18.24\n"
     ]
    }
   ],
   "source": [
    "resume_model = \"IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120_2\"\n",
    "num_samples = 5000\n",
    "\n",
    "exp_interpreter = exp + \"/train_datagan.json\" \n",
    "!bash docker_run.sh python train_interpreter_DB_SG2.py --generate_data True --exp=$exp_interpreter  --resume $resume_model  --num_sample=$num_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "Opt {'exp_dir': 'IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120', 'batch_size': 64, 'category': 'eyes_256', 'debug': False, 'dim': [256, 256, 4992], 'deeplab_res': 256, 'number_class': 4, 'testing_data_number_class': 4, 'max_training': 8, 'stylegan_ver': '2', 'annotation_data_from_w': False, 'annotation_mask_path': 'eyes_processed', 'testing_path': '', 'average_latent': 'avg_latent_stylegan.npy', 'annotation_image_latent_path': 'latent_stylegan.npy', 'stylegan_checkpoint': 'IJCB_EXPERIMENTS/checkpoints/IJCB_2022_checkpoints/CrossEyed_NIR_RGB_NEW_001120.pkl', 'model_num': 10, 'upsample_mode': 'bilinear', 'upsample_threshold': '8'}\n",
      "cp: 'IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120/train_datagan.json' and 'IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120/train_datagan.json' are the same file\n",
      "Generate data\n",
      "Eyes category\n",
      "---- Resolution: 256  Layers: 7\n",
      "---- Get avg latent\n",
      "---- Latent to torch\n",
      "AVG latent torch.Size([14, 512])\n",
      "----  Build Generator\n",
      "Resuming from \"IJCB_EXPERIMENTS/checkpoints/IJCB_2022_checkpoints/CrossEyed_NIR_RGB_NEW_001120.pkl\"\n",
      "Prepare StytleGAN2\n",
      "{'ref_gpus': 1, 'kimg': 25000, 'mb': -1, 'mbstd': -1, 'fmaps': -1, 'lrate': -1, 'gamma': -1, 'ema': -1, 'ramp': 0.05, 'map': 8}\n",
      "{'class_name': 'training_scripts_DB_SG2.networks.Generator', 'z_dim': 512, 'w_dim': 512, 'mapping_kwargs': {'num_layers': 8}, 'synthesis_kwargs': {'save_intermediate_results': True, 'channel_base': 16384, 'channel_max': 512, 'num_fp16_res': 4, 'conv_clamp': 256}}\n",
      "{'c_dim': 0, 'img_resolution': 256, 'img_channels': 3}\n",
      "Synthesis network:\n",
      "- Block resolutions: [4, 8, 16, 32, 64, 128, 256]\n",
      "- Channels dict: {4: 512, 8: 512, 16: 512, 32: 512, 64: 256, 128: 128, 256: 64}\n",
      "Generator(\n",
      "  (synthesis): SynthesisNetwork(\n",
      "    (b4): SynthesisBlock(\n",
      "      (conv1): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (torgb): ToRGBLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (toseg): ToSEGLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "    )\n",
      "    (b8): SynthesisBlock(\n",
      "      (conv0): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (conv1): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (torgb): ToRGBLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (toseg): ToSEGLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "    )\n",
      "    (b16): SynthesisBlock(\n",
      "      (conv0): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (conv1): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (torgb): ToRGBLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (toseg): ToSEGLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "    )\n",
      "    (b32): SynthesisBlock(\n",
      "      (conv0): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (conv1): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (torgb): ToRGBLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (toseg): ToSEGLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "    )\n",
      "    (b64): SynthesisBlock(\n",
      "      (conv0): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (conv1): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (torgb): ToRGBLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (toseg): ToSEGLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "    )\n",
      "    (b128): SynthesisBlock(\n",
      "      (conv0): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (conv1): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (torgb): ToRGBLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (toseg): ToSEGLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "    )\n",
      "    (b256): SynthesisBlock(\n",
      "      (conv0): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (conv1): SynthesisLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (torgb): ToRGBLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "      (toseg): ToSEGLayer(\n",
      "        (affine): FullyConnectedLayer()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mapping): MappingNetwork(\n",
      "    (fc0): FullyConnectedLayer()\n",
      "    (fc1): FullyConnectedLayer()\n",
      "    (fc2): FullyConnectedLayer()\n",
      "    (fc3): FullyConnectedLayer()\n",
      "    (fc4): FullyConnectedLayer()\n",
      "    (fc5): FullyConnectedLayer()\n",
      "    (fc6): FullyConnectedLayer()\n",
      "    (fc7): FullyConnectedLayer()\n",
      "  )\n",
      ")\n",
      "Resuming from \"IJCB_EXPERIMENTS/checkpoints/IJCB_2022_checkpoints/CrossEyed_NIR_RGB_NEW_001120.pkl\"\n",
      "synthesis.b4.const\n",
      "synthesis.b4.conv1.weight\n",
      "synthesis.b4.conv1.noise_strength\n",
      "synthesis.b4.conv1.bias\n",
      "synthesis.b4.conv1.affine.weight\n",
      "synthesis.b4.conv1.affine.bias\n",
      "synthesis.b4.torgb.weight\n",
      "synthesis.b4.torgb.bias\n",
      "synthesis.b4.torgb.affine.weight\n",
      "synthesis.b4.torgb.affine.bias\n",
      "synthesis.b4.toseg.weight\n",
      "synthesis.b4.toseg.bias\n",
      "synthesis.b4.toseg.affine.weight\n",
      "synthesis.b4.toseg.affine.bias\n",
      "synthesis.b8.conv0.weight\n",
      "synthesis.b8.conv0.noise_strength\n",
      "synthesis.b8.conv0.bias\n",
      "synthesis.b8.conv0.affine.weight\n",
      "synthesis.b8.conv0.affine.bias\n",
      "synthesis.b8.conv1.weight\n",
      "synthesis.b8.conv1.noise_strength\n",
      "synthesis.b8.conv1.bias\n",
      "synthesis.b8.conv1.affine.weight\n",
      "synthesis.b8.conv1.affine.bias\n",
      "synthesis.b8.torgb.weight\n",
      "synthesis.b8.torgb.bias\n",
      "synthesis.b8.torgb.affine.weight\n",
      "synthesis.b8.torgb.affine.bias\n",
      "synthesis.b8.toseg.weight\n",
      "synthesis.b8.toseg.bias\n",
      "synthesis.b8.toseg.affine.weight\n",
      "synthesis.b8.toseg.affine.bias\n",
      "synthesis.b16.conv0.weight\n",
      "synthesis.b16.conv0.noise_strength\n",
      "synthesis.b16.conv0.bias\n",
      "synthesis.b16.conv0.affine.weight\n",
      "synthesis.b16.conv0.affine.bias\n",
      "synthesis.b16.conv1.weight\n",
      "synthesis.b16.conv1.noise_strength\n",
      "synthesis.b16.conv1.bias\n",
      "synthesis.b16.conv1.affine.weight\n",
      "synthesis.b16.conv1.affine.bias\n",
      "synthesis.b16.torgb.weight\n",
      "synthesis.b16.torgb.bias\n",
      "synthesis.b16.torgb.affine.weight\n",
      "synthesis.b16.torgb.affine.bias\n",
      "synthesis.b16.toseg.weight\n",
      "synthesis.b16.toseg.bias\n",
      "synthesis.b16.toseg.affine.weight\n",
      "synthesis.b16.toseg.affine.bias\n",
      "synthesis.b32.conv0.weight\n",
      "synthesis.b32.conv0.noise_strength\n",
      "synthesis.b32.conv0.bias\n",
      "synthesis.b32.conv0.affine.weight\n",
      "synthesis.b32.conv0.affine.bias\n",
      "synthesis.b32.conv1.weight\n",
      "synthesis.b32.conv1.noise_strength\n",
      "synthesis.b32.conv1.bias\n",
      "synthesis.b32.conv1.affine.weight\n",
      "synthesis.b32.conv1.affine.bias\n",
      "synthesis.b32.torgb.weight\n",
      "synthesis.b32.torgb.bias\n",
      "synthesis.b32.torgb.affine.weight\n",
      "synthesis.b32.torgb.affine.bias\n",
      "synthesis.b32.toseg.weight\n",
      "synthesis.b32.toseg.bias\n",
      "synthesis.b32.toseg.affine.weight\n",
      "synthesis.b32.toseg.affine.bias\n",
      "synthesis.b64.conv0.weight\n",
      "synthesis.b64.conv0.noise_strength\n",
      "synthesis.b64.conv0.bias\n",
      "synthesis.b64.conv0.affine.weight\n",
      "synthesis.b64.conv0.affine.bias\n",
      "synthesis.b64.conv1.weight\n",
      "synthesis.b64.conv1.noise_strength\n",
      "synthesis.b64.conv1.bias\n",
      "synthesis.b64.conv1.affine.weight\n",
      "synthesis.b64.conv1.affine.bias\n",
      "synthesis.b64.torgb.weight\n",
      "synthesis.b64.torgb.bias\n",
      "synthesis.b64.torgb.affine.weight\n",
      "synthesis.b64.torgb.affine.bias\n",
      "synthesis.b64.toseg.weight\n",
      "synthesis.b64.toseg.bias\n",
      "synthesis.b64.toseg.affine.weight\n",
      "synthesis.b64.toseg.affine.bias\n",
      "synthesis.b128.conv0.weight\n",
      "synthesis.b128.conv0.noise_strength\n",
      "synthesis.b128.conv0.bias\n",
      "synthesis.b128.conv0.affine.weight\n",
      "synthesis.b128.conv0.affine.bias\n",
      "synthesis.b128.conv1.weight\n",
      "synthesis.b128.conv1.noise_strength\n",
      "synthesis.b128.conv1.bias\n",
      "synthesis.b128.conv1.affine.weight\n",
      "synthesis.b128.conv1.affine.bias\n",
      "synthesis.b128.torgb.weight\n",
      "synthesis.b128.torgb.bias\n",
      "synthesis.b128.torgb.affine.weight\n",
      "synthesis.b128.torgb.affine.bias\n",
      "synthesis.b128.toseg.weight\n",
      "synthesis.b128.toseg.bias\n",
      "synthesis.b128.toseg.affine.weight\n",
      "synthesis.b128.toseg.affine.bias\n",
      "synthesis.b256.conv0.weight\n",
      "synthesis.b256.conv0.noise_strength\n",
      "synthesis.b256.conv0.bias\n",
      "synthesis.b256.conv0.affine.weight\n",
      "synthesis.b256.conv0.affine.bias\n",
      "synthesis.b256.conv1.weight\n",
      "synthesis.b256.conv1.noise_strength\n",
      "synthesis.b256.conv1.bias\n",
      "synthesis.b256.conv1.affine.weight\n",
      "synthesis.b256.conv1.affine.bias\n",
      "synthesis.b256.torgb.weight\n",
      "synthesis.b256.torgb.bias\n",
      "synthesis.b256.torgb.affine.weight\n",
      "synthesis.b256.torgb.affine.bias\n",
      "synthesis.b256.toseg.weight\n",
      "synthesis.b256.toseg.bias\n",
      "synthesis.b256.toseg.affine.weight\n",
      "synthesis.b256.toseg.affine.bias\n",
      "mapping.fc0.weight\n",
      "mapping.fc0.bias\n",
      "mapping.fc1.weight\n",
      "mapping.fc1.bias\n",
      "mapping.fc2.weight\n",
      "mapping.fc2.bias\n",
      "mapping.fc3.weight\n",
      "mapping.fc3.bias\n",
      "mapping.fc4.weight\n",
      "mapping.fc4.bias\n",
      "mapping.fc5.weight\n",
      "mapping.fc5.bias\n",
      "mapping.fc6.weight\n",
      "mapping.fc6.bias\n",
      "mapping.fc7.weight\n",
      "mapping.fc7.bias\n",
      "synthesis.b4.resample_filter\n",
      "synthesis.b4.conv1.resample_filter\n",
      "synthesis.b4.conv1.noise_const\n",
      "synthesis.b8.resample_filter\n",
      "synthesis.b8.conv0.resample_filter\n",
      "synthesis.b8.conv0.noise_const\n",
      "synthesis.b8.conv1.resample_filter\n",
      "synthesis.b8.conv1.noise_const\n",
      "synthesis.b16.resample_filter\n",
      "synthesis.b16.conv0.resample_filter\n",
      "synthesis.b16.conv0.noise_const\n",
      "synthesis.b16.conv1.resample_filter\n",
      "synthesis.b16.conv1.noise_const\n",
      "synthesis.b32.resample_filter\n",
      "synthesis.b32.conv0.resample_filter\n",
      "synthesis.b32.conv0.noise_const\n",
      "synthesis.b32.conv1.resample_filter\n",
      "synthesis.b32.conv1.noise_const\n",
      "synthesis.b64.resample_filter\n",
      "synthesis.b64.conv0.resample_filter\n",
      "synthesis.b64.conv0.noise_const\n",
      "synthesis.b64.conv1.resample_filter\n",
      "synthesis.b64.conv1.noise_const\n",
      "synthesis.b128.resample_filter\n",
      "synthesis.b128.conv0.resample_filter\n",
      "synthesis.b128.conv0.noise_const\n",
      "synthesis.b128.conv1.resample_filter\n",
      "synthesis.b128.conv1.noise_const\n",
      "synthesis.b256.resample_filter\n",
      "synthesis.b256.conv0.resample_filter\n",
      "synthesis.b256.conv0.noise_const\n",
      "synthesis.b256.conv1.resample_filter\n",
      "synthesis.b256.conv1.noise_const\n",
      "mapping.w_avg\n",
      "======\n",
      "---- Parallel\n",
      "---- Create Upsamplers\n",
      "---- Done\n",
      "MODEL_NUMBER 0\n",
      "IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120/models/model_0.pth\n",
      "MODEL_NUMBER 1\n",
      "IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120/models/model_1.pth\n",
      "MODEL_NUMBER 2\n",
      "IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120/models/model_2.pth\n",
      "MODEL_NUMBER 3\n",
      "IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120/models/model_3.pth\n",
      "MODEL_NUMBER 4\n",
      "IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120/models/model_4.pth\n",
      "MODEL_NUMBER 5\n",
      "IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120/models/model_5.pth\n",
      "MODEL_NUMBER 6\n",
      "IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120/models/model_6.pth\n",
      "MODEL_NUMBER 7\n",
      "IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120/models/model_7.pth\n",
      "MODEL_NUMBER 8\n",
      "IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120/models/model_8.pth\n",
      "MODEL_NUMBER 9\n",
      "IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120/models/model_9.pth\n",
      "num_sample:  12\n",
      "  0%|                                                    | 0/12 [00:00<?, ?it/s]Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "Shape of one affine layer: torch.Size([1, 64, 256, 256])\n",
      "///  Len of affine layers: 14\n",
      "Affine layers from latent_to_image: torch.Size([4992, 256, 256])\n",
      "Affine layers post reshape, transpose: torch.Size([65536, 4992])\n",
      "  8%|███▋                                        | 1/12 [00:02<00:29,  2.67s/it]Shape of one affine layer: torch.Size([1, 64, 256, 256])\n",
      "///  Len of affine layers: 14\n",
      "Affine layers from latent_to_image: torch.Size([4992, 256, 256])\n",
      "Affine layers post reshape, transpose: torch.Size([65536, 4992])\n",
      " 17%|███████▎                                    | 2/12 [00:03<00:22,  2.24s/it]Shape of one affine layer: torch.Size([1, 64, 256, 256])\n",
      "///  Len of affine layers: 14\n",
      "Affine layers from latent_to_image: torch.Size([4992, 256, 256])\n",
      "Affine layers post reshape, transpose: torch.Size([65536, 4992])\n",
      " 25%|███████████                                 | 3/12 [00:05<00:17,  1.95s/it]Shape of one affine layer: torch.Size([1, 64, 256, 256])\n",
      "///  Len of affine layers: 14\n",
      "Affine layers from latent_to_image: torch.Size([4992, 256, 256])\n",
      "Affine layers post reshape, transpose: torch.Size([65536, 4992])\n",
      " 33%|██████████████▋                             | 4/12 [00:06<00:13,  1.74s/it]Shape of one affine layer: torch.Size([1, 64, 256, 256])\n",
      "///  Len of affine layers: 14\n",
      "Affine layers from latent_to_image: torch.Size([4992, 256, 256])\n",
      "Affine layers post reshape, transpose: torch.Size([65536, 4992])\n",
      " 42%|██████████████████▎                         | 5/12 [00:07<00:11,  1.59s/it]Shape of one affine layer: torch.Size([1, 64, 256, 256])\n",
      "///  Len of affine layers: 14\n",
      "Affine layers from latent_to_image: torch.Size([4992, 256, 256])\n",
      "Affine layers post reshape, transpose: torch.Size([65536, 4992])\n",
      " 50%|██████████████████████                      | 6/12 [00:08<00:08,  1.49s/it]Shape of one affine layer: torch.Size([1, 64, 256, 256])\n",
      "///  Len of affine layers: 14\n",
      "Affine layers from latent_to_image: torch.Size([4992, 256, 256])\n",
      "Affine layers post reshape, transpose: torch.Size([65536, 4992])\n",
      " 58%|█████████████████████████▋                  | 7/12 [00:10<00:07,  1.42s/it]Shape of one affine layer: torch.Size([1, 64, 256, 256])\n",
      "///  Len of affine layers: 14\n",
      "Affine layers from latent_to_image: torch.Size([4992, 256, 256])\n",
      "Affine layers post reshape, transpose: torch.Size([65536, 4992])\n",
      " 67%|█████████████████████████████▎              | 8/12 [00:11<00:05,  1.37s/it]Shape of one affine layer: torch.Size([1, 64, 256, 256])\n",
      "///  Len of affine layers: 14\n",
      "Affine layers from latent_to_image: torch.Size([4992, 256, 256])\n",
      "Affine layers post reshape, transpose: torch.Size([65536, 4992])\n",
      " 75%|█████████████████████████████████           | 9/12 [00:12<00:04,  1.34s/it]Shape of one affine layer: torch.Size([1, 64, 256, 256])\n",
      "///  Len of affine layers: 14\n",
      "Affine layers from latent_to_image: torch.Size([4992, 256, 256])\n",
      "Affine layers post reshape, transpose: torch.Size([65536, 4992])\n",
      " 83%|███████████████████████████████████▊       | 10/12 [00:13<00:02,  1.31s/it]Shape of one affine layer: torch.Size([1, 64, 256, 256])\n",
      "///  Len of affine layers: 14\n",
      "Affine layers from latent_to_image: torch.Size([4992, 256, 256])\n",
      "Affine layers post reshape, transpose: torch.Size([65536, 4992])\n",
      " 92%|███████████████████████████████████████▍   | 11/12 [00:15<00:01,  1.29s/it]Shape of one affine layer: torch.Size([1, 64, 256, 256])\n",
      "///  Len of affine layers: 14\n",
      "Affine layers from latent_to_image: torch.Size([4992, 256, 256])\n",
      "Affine layers post reshape, transpose: torch.Size([65536, 4992])\n",
      "100%|███████████████████████████████████████████| 12/12 [00:16<00:00,  1.37s/it]\n",
      "Run times:\n",
      "78.13 \\pm 0.18\n"
     ]
    }
   ],
   "source": [
    "#resume_model = \"IJCB_EXPERIMENTS/interpreter/CrossEyed_NIR_RGB_new_1120\"\n",
    "num_samples = 12\n",
    "\n",
    "exp_interpreter = exp + \"/train_datagan.json\" \n",
    "!bash docker_run.sh python train_interpreter_DB_SG2.py --generate_data True --exp=$exp_interpreter  --resume $resume_model  --num_sample=$num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "18479fac5746d32b43421ca5e0ee2dd5840b086e4ab03684aa8ec83129c0c31d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('dataGAN': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
